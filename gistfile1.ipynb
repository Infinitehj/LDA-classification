{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim and LDA: a quick tour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, fix the verbosity of the logger. In this example we're logging only warnings, but for a better debug, uprint all the INFOs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.WARNING)\n",
    "logging.root.level = logging.WARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to get some textual data. We're gonna use the 20 newsgroups dataset (more info here: http://qwone.com/~jason/20Newsgroups). As stated by its creators, it is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups.\n",
    "\n",
    "To make things more real, we're remving email headers, footers (like signatures) and quoted messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "news_dataset = datasets.fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the dataset there are 18846 textual documents\n",
      "And this is the first one:\n",
      " \n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A list of text document is contained in the data variable\n",
    "documents = news_dataset.data\n",
    "\n",
    "print (\"In the dataset there are\", len(documents), \"textual documents\")\n",
    "print (\"And this is the first one:\\n\", documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do now have a collection of documents. Let's start with some preprocessing steps. At first, we're gonna import all the modules we need. Then, we define a word tokenizer (https://en.wikipedia.org/wiki/Tokenization_(lexical_analysis)) with stopword removal (common words like \"the\", \"are\" and \"and\" are excuded from the processing, since they don't have discriminative power and they just increase the processing complexity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the tokenizer, the previous document becomes:\n",
      " ['sure', 'bashers', 'pens', 'fans', 'pretty', 'confused', 'lack', 'kind', 'posts', 'recent', 'pens', 'massacre', 'devils', 'actually', 'bit', 'puzzled', 'bit', 'relieved', 'going', 'end', 'non', 'pittsburghers', 'relief', 'bit', 'praise', 'pens', 'man', 'killing', 'devils', 'worse', 'thought', 'jagr', 'showed', 'better', 'regular', 'season', 'stats', 'lot', 'fo', 'fun', 'watch', 'playoffs', 'bowman', 'let', 'jagr', 'lot', 'fun', 'couple', 'games', 'pens', 'going', 'beat', 'pulp', 'jersey', 'disappointed', 'islanders', 'lose', 'final', 'regular', 'season', 'game', 'pens', 'rule']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return [token for token in gensim.utils.simple_preprocess(text) if token not in gensim.parsing.preprocessing.STOPWORDS]\n",
    "\n",
    "print (\"After the tokenizer, the previous document becomes:\\n\", tokenize(documents[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: tokenise all the documents and build a count dictionary, that contains the count of the tokens over the complete text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the corpus there are 95507 unique tokens\n"
     ]
    }
   ],
   "source": [
    "processed_docs = [tokenize(doc) for doc in documents]\n",
    "word_count_dict = gensim.corpora.Dictionary(processed_docs)\n",
    "print (\"In the corpus there are\", len(word_count_dict), \"unique tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to further lower the complexity of the process, removing all the very rare tokens (the ones appearing in less than 20 documents) and the very popular ones (the ones appearing in more than 20% documents; in our case circa 4'000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_dict.filter_extremes(no_below=20, no_above=0.1) # word must appear >10 times, and no more than 20% documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, in the corpus there are only 8121 unique tokens\n"
     ]
    }
   ],
   "source": [
    "print (\"After filtering, in the corpus there are only\", len(word_count_dict), \"unique tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not build the bag of words representation (https://en.wikipedia.org/wiki/Bag-of-words_model) of the text documents, to create a nice vector space model (https://en.wikipedia.org/wiki/Vector_space_model). Within this methaphor, a vector lists the multiplicity of the tokens appearing in the document. The vector is indexed by the dictionary of tokens, previously built. Note that, since a restricted subset of words appears in each document, this vector is often represented in a sparse way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag_of_words_corpus = [word_count_dict.doc2bow(pdoc) for pdoc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words representation of the first document (tuples are composed by token_id and multiplicity):\n",
      " [(23, 1), (341, 2), (425, 1), (450, 1), (493, 1), (514, 1), (535, 1), (808, 1), (1381, 1), (1811, 2), (1978, 1), (1987, 1), (2761, 1), (2954, 3), (3146, 1), (3232, 1), (3549, 1), (3866, 5), (3973, 1), (4015, 1), (4177, 1), (4662, 2), (5046, 2), (5052, 2), (5156, 1), (5250, 1), (5263, 2), (5447, 1), (5586, 1), (5958, 2), (5968, 1), (5999, 1), (6084, 1), (6179, 1), (6202, 1), (6512, 1), (6896, 1), (7100, 1), (7231, 1), (7380, 1), (7414, 1), (7463, 1), (7476, 1), (7837, 1)]\n",
      "In the document, topic_id 23 (word \"final\") appears 1 time[s]\n",
      "In the document, topic_id 341 (word \"regular\") appears 2 time[s]\n",
      "In the document, topic_id 425 (word \"worse\") appears 1 time[s]\n",
      "In the document, topic_id 450 (word \"posts\") appears 1 time[s]\n",
      "In the document, topic_id 493 (word \"beat\") appears 1 time[s]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "bow_doc1 = bag_of_words_corpus[0]\n",
    "\n",
    "print (\"Bag of words representation of the first document (tuples are composed by token_id and multiplicity):\\n\", bow_doc1)\n",
    "print\n",
    "for i in range(5):\n",
    "    print (\"In the document, topic_id {} (word \\\"{}\\\") appears {} time[s]\".format(bow_doc1[i][0], word_count_dict[bow_doc1[i][0]], bow_doc1[i][1]))\n",
    "print (\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally, the core algorithm of the analysis: LDA. Gensim offers two implementations: a monocore one, and a multicore. We use the monocore one, setting the number of topics equal to 10 (you can change it, and check the results). Try themulticore to prove the speedup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LDA mono-core\n",
    "lda_model = gensim.models.LdaModel(bag_of_words_corpus, num_topics=10, id2word=word_count_dict, passes=5)\n",
    "\n",
    "# LDA multicore (in this configuration, defaulty, uses n_cores-1)\n",
    "# lda_model = gensim.models.LdaMulticore(bag_of_words_corpus, num_topics=10, id2word=word_count_dict, passes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a list of the words (and their relative weights) for each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.024*edu + 0.017*com + 0.016*dos + 0.013*windows + 0.010*software + 0.009*mail + 0.007*data + 0.007*ftp + 0.006*pc + 0.006*space'),\n",
       " (1,\n",
       "  '0.015*file + 0.014*image + 0.009*program + 0.008*key + 0.008*files + 0.007*code + 0.007*window + 0.006*bit + 0.006*data + 0.006*available'),\n",
       " (2,\n",
       "  '0.010*drive + 0.007*car + 0.007*card + 0.006*problem + 0.006*mb + 0.005*power + 0.005*disk + 0.005*work + 0.005*hard + 0.005*scsi'),\n",
       " (3,\n",
       "  '0.014*game + 0.012*team + 0.010*year + 0.009*games + 0.006*play + 0.006*season + 0.006*hockey + 0.006*st + 0.005*league + 0.005*players'),\n",
       " (4,\n",
       "  '0.008*space + 0.007*information + 0.006*book + 0.006*research + 0.005*list + 0.005*earth + 0.005*mail + 0.004*university + 0.004*books + 0.004*number'),\n",
       " (5,\n",
       "  '0.029*god + 0.008*jesus + 0.008*believe + 0.007*bible + 0.007*church + 0.006*christian + 0.006*christ + 0.005*religion + 0.005*word + 0.005*christians'),\n",
       " (6,\n",
       "  '0.502*ax + 0.038*max + 0.008*pl + 0.006*di + 0.005*tm + 0.005*ei + 0.005*wm + 0.004*mk + 0.004*mv + 0.004*mr'),\n",
       " (7,\n",
       "  '0.010*israel + 0.009*jews + 0.008*war + 0.008*armenian + 0.007*armenians + 0.007*turkish + 0.006*said + 0.006*world + 0.005*israeli + 0.005*turkey'),\n",
       " (8,\n",
       "  '0.008*government + 0.006*law + 0.005*mr + 0.005*public + 0.005*gun + 0.004*going + 0.004*president + 0.004*state + 0.003*fbi + 0.003*encryption'),\n",
       " (9,\n",
       "  '0.006*said + 0.006*years + 0.005*going + 0.004*day + 0.004*long + 0.004*things + 0.004*little + 0.004*ll + 0.004*maybe + 0.004*probably')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = lda_model.print_topics(-1)\n",
    "_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print now the topics composition, and their scores, for the first document. You will see that only few topics are represented; the others have a nil score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8918003347989151\t Topic: 0.014*game + 0.012*team + 0.010*year + 0.009*games + 0.006*play + 0.006*season + 0.006*hockey + 0.006*st + 0.005*league + 0.005*players\n",
      "Score: 0.058134711534788046\t Topic: 0.010*israel + 0.009*jews + 0.008*war + 0.008*armenian + 0.007*armenians + 0.007*turkish + 0.006*said + 0.006*world + 0.005*israeli + 0.005*turkey\n",
      "Score: 0.03799283096267246\t Topic: 0.006*said + 0.006*years + 0.005*going + 0.004*day + 0.004*long + 0.004*things + 0.004*little + 0.004*ll + 0.004*maybe + 0.004*probably\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bag_of_words_corpus[0]], key=lambda tup: -1*tup[1]):\n",
    "    print (\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's wonderful! LDA is able to understand that the article is about a team game, hockey, even though the work hockey *never* appears in the document. Checking the ground truth for that document (the newsgroup category) it's actually correct! It was posted in sport/hockey category. Other topics, if any, account for less than 5%, so they have to be considered marginals (dirt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.hockey'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.target_names[news_dataset.target[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have dealt with documents contained in the training set. What if we need to process an unseed document? Fortunately, we don't need to re-train the system (wasting lots of time), as we can just infer its topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unseen document is composed by the following text: In my spare time I either play badmington or drive my car\n",
      "Score: 0.6350347340119411\t Topic: 0.010*drive + 0.007*car + 0.007*card + 0.006*problem + 0.006*mb\n",
      "Score: 0.20496338560082367\t Topic: 0.014*game + 0.012*team + 0.010*year + 0.009*games + 0.006*play\n",
      "Score: 0.020000636871351535\t Topic: 0.006*said + 0.006*years + 0.005*going + 0.004*day + 0.004*long\n",
      "Score: 0.02000037465176586\t Topic: 0.008*government + 0.006*law + 0.005*mr + 0.005*public + 0.005*gun\n",
      "Score: 0.02000034610222013\t Topic: 0.024*edu + 0.017*com + 0.016*dos + 0.013*windows + 0.010*software\n",
      "Score: 0.02000032246553001\t Topic: 0.029*god + 0.008*jesus + 0.008*believe + 0.007*bible + 0.007*church\n",
      "Score: 0.020000200286856618\t Topic: 0.010*israel + 0.009*jews + 0.008*war + 0.008*armenian + 0.007*armenians\n",
      "Score: 0.02000000000540921\t Topic: 0.008*space + 0.007*information + 0.006*book + 0.006*research + 0.005*list\n",
      "Score: 0.020000000002613573\t Topic: 0.502*ax + 0.038*max + 0.008*pl + 0.006*di + 0.005*tm\n",
      "Score: 0.020000000001488268\t Topic: 0.015*file + 0.014*image + 0.009*program + 0.008*key + 0.008*files\n"
     ]
    }
   ],
   "source": [
    "unseen_document = \"In my spare time I either play badmington or drive my car\"\n",
    "print (\"The unseen document is composed by the following text:\", unseen_document)\n",
    "print\n",
    "\n",
    "bow_vector = word_count_dict.doc2bow(tokenize(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print (\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log perplexity of the model is -7.62681524056\n"
     ]
    }
   ],
   "source": [
    "print (\"Log perplexity of the model is\", lda_model.log_perplexity(bag_of_words_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
