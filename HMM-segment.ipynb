{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baum_welch(pi,A,B):\n",
    "    f = file(\".\\\\1.txt\")\n",
    "    sentence = f.read()[3:].decode('utf-8')\n",
    "    f.close()\n",
    "    T = len(sentenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 二元隐马尔科夫模型（Bigram HMMs）\n",
    "# 'trainCorpus.txt_utf8'为人民日报已经人工分词的预料，29万多条句子\n",
    "\n",
    "import sys\n",
    "\n",
    "#state_M = 4\n",
    "#word_N = 0\n",
    "A_dic = {}\n",
    "B_dic = {}\n",
    "Count_dic = {}\n",
    "Pi_dic = {}\n",
    "word_set = set()\n",
    "state_list = ['B','M','E','S']\n",
    "line_num = -1\n",
    "\n",
    "INPUT_DATA = \"trainCorpus.txt_utf8\"\n",
    "PROB_START = \"trainHMM\\prob_start.py\"   #初始状态概率\n",
    "PROB_EMIT = \"trainHMM\\prob_emit.py\"     #发射概率\n",
    "PROB_TRANS = \"trainHMM\\prob_trans.py\"   #转移概率\n",
    "\n",
    "\n",
    "def init():  #初始化字典\n",
    "    #global state_M\n",
    "    #global word_N\n",
    "    for state in state_list:\n",
    "        A_dic[state] = {}\n",
    "        for state1 in state_list:\n",
    "            A_dic[state][state1] = 0.0\n",
    "    for state in state_list:\n",
    "        Pi_dic[state] = 0.0\n",
    "        B_dic[state] = {}\n",
    "        Count_dic[state] = 0\n",
    "\n",
    "\n",
    "def getList(input_str):  #输入词语，输出状态\n",
    "    outpout_str = []\n",
    "    if len(input_str) == 1:\n",
    "        outpout_str.append('S')\n",
    "    elif len(input_str) == 2:\n",
    "        outpout_str = ['B','E']\n",
    "    else:\n",
    "        M_num = len(input_str) -2\n",
    "        M_list = ['M'] * M_num\n",
    "        outpout_str.append('B')\n",
    "        outpout_str.extend(M_list)  #把M_list中的'M'分别添加进去\n",
    "        outpout_str.append('E')\n",
    "    return outpout_str\n",
    "\n",
    "\n",
    "def Output():   #输出模型的三个参数：初始概率+转移概率+发射概率\n",
    "    start_fp = file(PROB_START,'w')\n",
    "    emit_fp = file(PROB_EMIT,'w')\n",
    "    trans_fp = file(PROB_TRANS,'w')\n",
    "    print \"len(word_set) = %s \" % (len(word_set))\n",
    "\n",
    "    for key in Pi_dic:           #状态的初始概率\n",
    "        Pi_dic[key] = Pi_dic[key] * 1.0 / line_num\n",
    "    print >>start_fp,Pi_dic\n",
    "\n",
    "    for key in A_dic:            #状态转移概率\n",
    "        for key1 in A_dic[key]:\n",
    "            A_dic[key][key1] = A_dic[key][key1] / Count_dic[key]\n",
    "    print >>trans_fp,A_dic\n",
    "\n",
    "    for key in B_dic:            #发射概率(状态->词语的条件概率)\n",
    "        for word in B_dic[key]:\n",
    "            B_dic[key][word] = B_dic[key][word] / Count_dic[key]\n",
    "    print >>emit_fp,B_dic\n",
    "\n",
    "    start_fp.close()\n",
    "    emit_fp.close()\n",
    "    trans_fp.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    ifp = file(INPUT_DATA)\n",
    "    init()\n",
    "    global word_set   #初始是set()\n",
    "    global line_num   #初始是-1\n",
    "    for line in ifp:\n",
    "        line_num += 1\n",
    "        if line_num % 10000 == 0:\n",
    "            print line_num\n",
    "\n",
    "        line = line.strip()\n",
    "        if not line:continue\n",
    "        line = line.decode(\"utf-8\",\"ignore\")  #设置为ignore，会忽略非法字符\n",
    "\n",
    "\n",
    "        word_list = []\n",
    "        for i in range(len(line)):\n",
    "            if line[i] == \" \":continue\n",
    "            word_list.append(line[i])\n",
    "        word_set = word_set | set(word_list)   #训练预料库中所有字的集合\n",
    "\n",
    "\n",
    "        lineArr = line.split(\" \")\n",
    "        line_state = []\n",
    "        for item in lineArr:\n",
    "            line_state.extend(getList(item))   #一句话对应一行连续的状态\n",
    "        if len(word_list) != len(line_state):\n",
    "            print >> sys.stderr,\"[line_num = %d][line = %s]\" % (line_num, line.endoce(\"utf-8\",'ignore'))\n",
    "        else:\n",
    "            for i in range(len(line_state)):\n",
    "                if i == 0:\n",
    "                    Pi_dic[line_state[0]] += 1      #Pi_dic记录句子第一个字的状态，用于计算初始状态概率\n",
    "                    Count_dic[line_state[0]] += 1   #记录每一个状态的出现次数\n",
    "                else:\n",
    "                    A_dic[line_state[i-1]][line_state[i]] += 1    #用于计算转移概率\n",
    "                    Count_dic[line_state[i]] += 1\n",
    "                    if not B_dic[line_state[i]].has_key(word_list[i]):\n",
    "                        B_dic[line_state[i]][word_list[i]] = 0.0\n",
    "                    else:\n",
    "                        B_dic[line_state[i]][word_list[i]] += 1   #用于计算发射概率\n",
    "    Output()\n",
    "    ifp.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "def load_model(f_name):\n",
    "    ifp = file(f_name, 'rb')\n",
    "    return eval(ifp.read())  #eval参数是一个字符串, 可以把这个字符串当成表达式来求值,\n",
    "\n",
    "\n",
    "prob_start = load_model(\"trainHMM\\prob_start.py\")\n",
    "prob_trans = load_model(\"trainHMM\\prob_trans.py\")\n",
    "prob_emit = load_model(\"trainHMM\\prob_emit.py\")\n",
    "\n",
    "\n",
    "def viterbi(obs, states, start_p, trans_p, emit_p):  #维特比算法（一种递归算法）\n",
    "    V = [{}]\n",
    "    path = {}\n",
    "    for y in states:   #初始值\n",
    "        V[0][y] = start_p[y] * emit_p[y].get(obs[0],0)   #在位置0，以y状态为末尾的状态序列的最大概率\n",
    "        path[y] = [y]\n",
    "    for t in range(1,len(obs)):\n",
    "        V.append({})\n",
    "        newpath = {}\n",
    "        for y in states:      #从y0 -> y状态的递归\n",
    "            (prob, state) = max([(V[t-1][y0] * trans_p[y0].get(y,0) * emit_p[y].get(obs[t],0) ,y0) for y0 in states if V[t-1][y0]>0])\n",
    "            V[t][y] =prob\n",
    "            newpath[y] = path[state] + [y]\n",
    "        path = newpath  #记录状态序列\n",
    "    (prob, state) = max([(V[len(obs) - 1][y], y) for y in states])  #在最后一个位置，以y状态为末尾的状态序列的最大概率\n",
    "    return (prob, path[state])  #返回概率和状态序列\n",
    "\n",
    "\n",
    "def cut(sentence):\n",
    "    prob, pos_list =  viterbi(sentence,('B','M','E','S'), prob_start, prob_trans, prob_emit)\n",
    "    return (prob,pos_list)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_str = u\"新华网驻东京记者报道\"\n",
    "    prob,pos_list = cut(test_str)\n",
    "    print test_str\n",
    "    print pos_list"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
