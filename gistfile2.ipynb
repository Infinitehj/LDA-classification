{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the dataset there are 10746 textual documents\n",
      "Running time: 33.81098931955416 Seconds\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.WARNING)\n",
    "logging.root.level = logging.WARNING\n",
    "\n",
    "import os\n",
    "import jieba\n",
    "import codecs\n",
    "import time\n",
    "start = time.clock()\n",
    "documents = []\n",
    "walk = os.walk('train')\n",
    "for root ,dirs, files in walk:\n",
    "    for name in files:\n",
    "        #documents.append([])\n",
    "        filename = os.path.join(root, name)\n",
    "        try:\n",
    "            f = open(filename)\n",
    "            #f = codecs.open(filename,'r','utf-8','ignore')\n",
    "            text = f.read()\n",
    "        except:\n",
    "            f = codecs.open(filename,'r','gbk','ignore')    \n",
    "            text = f.read()\n",
    "        finally:\n",
    "            f.close()\n",
    "        \n",
    "        documents.append(text)\n",
    "#documents = news_dataset.data\n",
    "\n",
    "print (\"In the dataset there are\", len(documents), \"textual documents\")\n",
    "end = time.clock()\n",
    "print('Running time: %s Seconds'%(end-start))\n",
    "#print (\"And this is the first one:\\n\", documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\dell\\AppData\\Local\\Temp\\jieba.cache\n",
      "DEBUG:jieba:Loading model from cache C:\\Users\\dell\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.445 seconds.\n",
      "DEBUG:jieba:Loading model cost 1.445 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the corpus there are 216313 unique tokens\n",
      "Running time: 407.2669569576021 Seconds\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import time\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "start = time.clock()        \n",
    "def load_stopwords():\n",
    "    f_stop = open('stopwords.txt')\n",
    "    try:\n",
    "        f_stop_text = f_stop.read()\n",
    "\n",
    "    finally:\n",
    "        f_stop.close()\n",
    "\n",
    "    f_stop_seg_list = f_stop_text.split('\\n')\n",
    "    return f_stop_seg_list\n",
    "\n",
    "def tokenize(text):\n",
    "    stopwords = load_stopwords()    \n",
    "\n",
    "    return [token for token in jieba.cut(text) if token.strip() not in stopwords and len(token.strip()) > 1]\n",
    "\n",
    "#print (\"After the tokenizer, the previous document becomes:\\n\", tokenize(documents[0]))\n",
    "\n",
    "processed_docs = [tokenize(doc) for doc in documents]\n",
    "word_count_dict = gensim.corpora.Dictionary(processed_docs)\n",
    "print (\"In the corpus there are\", len(word_count_dict), \"unique tokens\")\n",
    "\n",
    "end = time.clock()\n",
    "print('Running time: %s Seconds'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, in the corpus there are only 15697 unique tokens\n",
      "In the document, topic_id 91 (word \"方便\") appears 1 time[s]\n",
      "In the document, topic_id 142 (word \"心理\") appears 1 time[s]\n",
      "In the document, topic_id 150 (word \"单一\") appears 1 time[s]\n",
      "In the document, topic_id 204 (word \"原始\") appears 1 time[s]\n",
      "In the document, topic_id 212 (word \"回复\") appears 1 time[s]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "word_count_dict.filter_extremes(no_below=20, no_above=0.1) # word must appear >10 times, and no more than 20% documents\n",
    "print (\"After filtering, in the corpus there are only\", len(word_count_dict), \"unique tokens\")\n",
    "\n",
    "bag_of_words_corpus = [word_count_dict.doc2bow(pdoc) for pdoc in processed_docs]\n",
    "\n",
    "bow_doc1 = bag_of_words_corpus[0]\n",
    "\n",
    "#print (\"Bag of words representation of the first document (tuples are composed by token_id and multiplicity):\\n\", bow_doc1)\n",
    "print\n",
    "for i in range(5):\n",
    "    print (\"In the document, topic_id {} (word \\\"{}\\\") appears {} time[s]\".format(bow_doc1[i][0], word_count_dict[bow_doc1[i][0]], bow_doc1[i][1]))\n",
    "print (\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 264.9332727682497 Seconds\n",
      "Running time: 274.0514030067159 Seconds\n",
      "Running time: 269.13075202375103 Seconds\n",
      "Running time: 281.0575423028499 Seconds\n",
      "Running time: 278.3851060798943 Seconds\n",
      "[-8.4073949386240194, -8.4535082181200831, -8.4753371336751471, -8.4235092637521234, -8.4105535283007384]\n"
     ]
    }
   ],
   "source": [
    "# LDA mono-core\n",
    "\n",
    "lper = []\n",
    "topiclist=[10,50,100,150,200]\n",
    "for ntopic in topiclist:\n",
    "    start = time.clock()\n",
    "    lda_model = gensim.models.LdaModel(bag_of_words_corpus, num_topics=10, iterations=50,id2word=word_count_dict, passes=5)\n",
    "    lper.append(lda_model.log_perplexity(bag_of_words_corpus))\n",
    "    end = time.clock()\n",
    "    print('Running time: %s Seconds'%(end-start))\n",
    "print(lper)\n",
    "# LDA multicore (in this configuration, defaulty, uses n_cores-1)\n",
    "# lda_model = gensim.models.LdaMulticore(bag_of_words_corpus, num_topics=10, id2word=word_count_dict, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [10,50,100,150,200]\n",
    "y = [-8.4073949386240194, -8.4535082181200831, -8.4753371336751471, -8.4235092637521234, -8.4105535283007384]\n",
    "print(\"num_topics: \",x)\n",
    "print(\"log_perplexity: \",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = topiclist\n",
    "y = lper\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('num_topics')\n",
    "plt.ylabel('log_perplexity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 395.0832628952928 Seconds\n",
      "Running time: 407.13549432725745 Seconds\n",
      "Running time: 453.2519036744234 Seconds\n",
      "Running time: 433.957688734607 Seconds\n",
      "Running time: 440.8043389285567 Seconds\n",
      "[-8.3791937643393357, -8.4174283251262967, -8.4782422181183055, -8.4869577030165431, -8.4742420426931737]\n"
     ]
    }
   ],
   "source": [
    "# LDA mono-core\n",
    "\n",
    "lper2 = []\n",
    "iteration =[50,100,500,1000,2000]\n",
    "for iternum in iteration:\n",
    "    start = time.clock()\n",
    "    lda_model = gensim.models.LdaModel(bag_of_words_corpus, num_topics=100, iterations=iternum,id2word=word_count_dict, passes=5)\n",
    "    lper2.append(lda_model.log_perplexity(bag_of_words_corpus))\n",
    "    end = time.clock()\n",
    "    print('Running time: %s Seconds'%(end-start))\n",
    "print(lper2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x =[50,100,500,1000,2000]\n",
    "y =[-8.3791937643393357, -8.4174283251262967, -8.4782422181183055, -8.4869577030165431, -8.4742420426931737]\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = topiclist\n",
    "y = lper\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('num_topics')\n",
    "plt.ylabel('log_perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 302.9477119165567 Seconds\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "\n",
    "start = time.clock()\n",
    "lda_model = gensim.models.LdaModel(bag_of_words_corpus, num_topics=100, iterations=1000,id2word=word_count_dict, passes=5)\n",
    "end = time.clock()\n",
    "print('Running time: %s Seconds'%(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __init__(self, corpus=None, num_topics=100, id2word=None, distributed=False, chunksize=2000, passes=1, update_every=1, alpha='symmetric', eta=None, decay=0.5, offset=1.0, eval_every=10, iterations=50, gamma_threshold=0.001, minimum_probability=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.021*孩子 + 0.019*知识 + 0.014*喜欢 + 0.011*压力 + 0.010*家庭 + 0.010*努力 + 0.008*生命 + 0.008*理解 + 0.007*兴趣 + 0.007*自信'),\n",
       " (1,\n",
       "  '0.043*有限公司 + 0.030*股份 + 0.026*股东 + 0.021*股权 + 0.017*投资 + 0.016*论坛 + 0.014*深圳 + 0.014*集团 + 0.014*亿元 + 0.012*万元'),\n",
       " (2,\n",
       "  '0.049*采购 + 0.048*出口 + 0.041*北约 + 0.037*综合 + 0.028*战时 + 0.027*预警 + 0.026*国产 + 0.022*任务 + 0.021*通信 + 0.021*该机'),\n",
       " (3,\n",
       "  '0.060*搜索 + 0.051*com + 0.044*www + 0.037*搜狗 + 0.036*互联网 + 0.033*sogou + 0.030*网站 + 0.025*行业 + 0.018*注册 + 0.017*律师'),\n",
       " (4,\n",
       "  '0.178*日本 + 0.009*人体 + 0.008*危机 + 0.008*击败 + 0.007*日本政府 + 0.007*解释 + 0.007*中日 + 0.007*&# + 0.006*失败 + 0.006*威胁'),\n",
       " (5,\n",
       "  '0.053*战争 + 0.021*力量 + 0.016*民族 + 0.013*精神 + 0.011*皇帝 + 0.011*威胁 + 0.011*时代 + 0.010*传统 + 0.008*背景 + 0.008*地位'),\n",
       " (6,\n",
       "  '0.066*合同 + 0.057*协议 + 0.027*签订 + 0.025*签署 + 0.024*名称 + 0.018*II + 0.018*依据 + 0.017*打赢 + 0.015*支付 + 0.015*签证'),\n",
       " (7,\n",
       "  '0.024*调查 + 0.015*科目 + 0.014*农民 + 0.013*农村 + 0.010*解决 + 0.009*命令 + 0.008*锻炼 + 0.007*方法 + 0.007*企图 + 0.007*动员'),\n",
       " (8,\n",
       "  '0.197*职业 + 0.037*高原 + 0.036*西安 + 0.027*证书 + 0.021*投诉 + 0.018*植物 + 0.018*咨询 + 0.015*南京 + 0.015*诚信 + 0.015*经理人'),\n",
       " (9,\n",
       "  '0.057*核弹头 + 0.047*两军 + 0.039*空降兵 + 0.036*刘邦 + 0.029*林肯 + 0.021*文科 + 0.020*鲁迅 + 0.019*中国队 + 0.018*奖金 + 0.017*快艇'),\n",
       " (10,\n",
       "  '0.072*比赛 + 0.046*侦察 + 0.023*球队 + 0.019*联赛 + 0.013*冠军 + 0.012*主场 + 0.010*这场 + 0.010*决赛 + 0.010*进球 + 0.010*小分队'),\n",
       " (11,\n",
       "  '0.058*年度 + 0.045*修理 + 0.025*授予 + 0.022*大使 + 0.020*筹建 + 0.019*艺术品 + 0.019*革命性 + 0.018*草案 + 0.018*can + 0.017*报告'),\n",
       " (12,\n",
       "  '0.038*攻关 + 0.036*科研 + 0.036*加工 + 0.020*医药 + 0.020*计算机 + 0.019*重型 + 0.018*生产 + 0.015*节点 + 0.011*部件 + 0.011*机械'),\n",
       " (13,\n",
       "  '0.046*that + 0.034*are + 0.034*概论 + 0.033*be + 0.021*军火 + 0.019*at + 0.019*by + 0.019*was + 0.018*月薪 + 0.016*one'),\n",
       " (14,\n",
       "  '0.042*实战 + 0.033*应届 + 0.032*推荐 + 0.025*维和 + 0.023*代表团 + 0.022*密集 + 0.021*东北 + 0.020*下达 + 0.016*生物 + 0.015*细胞'),\n",
       " (15,\n",
       "  '0.137*训练 + 0.072*飞行 + 0.033*战斗力 + 0.026*飞行员 + 0.015*任务 + 0.015*发射 + 0.012*模拟 + 0.012*交付 + 0.011*节目 + 0.011*高度'),\n",
       " (16,\n",
       "  '0.038*战斗机 + 0.019*武器装备 + 0.017*老板 + 0.013*同事 + 0.012*米格 + 0.009*职场 + 0.009*办公室 + 0.009*跳槽 + 0.006*白领 + 0.006*反恐'),\n",
       " (17,\n",
       "  '0.059*集团 + 0.054*基地 + 0.044*陆军 + 0.019*集团公司 + 0.017*现役 + 0.016*开发 + 0.016*工程 + 0.015*西部 + 0.014*铁路 + 0.014*贵州'),\n",
       " (18,\n",
       "  '0.030*创作 + 0.024*作品 + 0.022*论证 + 0.021*现象 + 0.018*结论 + 0.017*认证 + 0.016*前提 + 0.015*绿色 + 0.013*形式 + 0.013*环保'),\n",
       " (19,\n",
       "  '0.025*收入 + 0.015*材料 + 0.015*消费 + 0.014*房子 + 0.013*作文 + 0.012*话题 + 0.011*故事 + 0.010*听力 + 0.009*名人 + 0.008*词汇'),\n",
       " (20,\n",
       "  '0.261*部队 + 0.042*战术 + 0.037*gt + 0.014*集团军 + 0.011*分队 + 0.010*教练 + 0.009*访谈 + 0.008*课题 + 0.008*行动 + 0.007*复杂'),\n",
       " (21,\n",
       "  '0.056*装备 + 0.046*试验 + 0.035*飞机 + 0.034*系统 + 0.022*军方 + 0.020*设计 + 0.020*英国 + 0.017*国防部 + 0.017*性能 + 0.016*战斗'),\n",
       " (22,\n",
       "  '0.021*冲突 + 0.019*势力 + 0.017*IT + 0.014*生涯 + 0.012*担任 + 0.012*地位 + 0.011*内部 + 0.011*收入 + 0.011*独立 + 0.010*牵制'),\n",
       " (23,\n",
       "  '0.007*一句 + 0.007*一边 + 0.006*东西 + 0.006*一天 + 0.006*有人 + 0.005*以前 + 0.005*自由 + 0.005*过来 + 0.005*旅客 + 0.005*几个'),\n",
       " (24,\n",
       "  '0.019*隐形 + 0.015*年代 + 0.012*联合国 + 0.011*战备 + 0.011*世纪 + 0.010*海军陆战队 + 0.010*公元前 + 0.009*古代 + 0.008*战争 + 0.008*建筑'),\n",
       " (25,\n",
       "  '0.074*工资 + 0.044*公务员 + 0.040*招聘会 + 0.036*广州 + 0.034*劳动 + 0.023*单词 + 0.022*劳动者 + 0.019*句子 + 0.018*用人单位 + 0.017*中文'),\n",
       " (26,\n",
       "  '0.022*直升机 + 0.018*敌人 + 0.015*阅读 + 0.013*文章 + 0.013*政治 + 0.012*青年 + 0.011*思想 + 0.011*出版 + 0.010*作品 + 0.010*作者'),\n",
       " (27,\n",
       "  '0.026*增长 + 0.016*上涨 + 0.015*行情 + 0.015*指数 + 0.010*第五代 + 0.009*行业 + 0.009*论坛 + 0.009*大幅 + 0.009*投资者 + 0.008*个股'),\n",
       " (28,\n",
       "  '0.112*韩国 + 0.032*太阳 + 0.030*外交 + 0.027*突袭 + 0.026*祖国 + 0.026*千米 + 0.023*测量 + 0.020*杂志 + 0.019*东方 + 0.017*日美'),\n",
       " (29,\n",
       "  '0.021*25 + 0.019*75 + 0.018*基金 + 0.018*后备 + 0.017*雅龙 + 0.015*01 + 0.015*投资 + 0.013*26 + 0.013*古巴 + 0.011*40'),\n",
       " (30,\n",
       "  '0.086*香港 + 0.028*派出 + 0.026*52 + 0.025*天津 + 0.022*防守 + 0.018*联盟 + 0.014*99 + 0.014*减肥 + 0.011*91 + 0.010*最佳'),\n",
       " (31,\n",
       "  '0.021*教育部 + 0.017*学费 + 0.014*单位 + 0.013*举办 + 0.012*学校 + 0.012*优秀 + 0.011*校长 + 0.011*入学 + 0.011*万元 + 0.010*自治区'),\n",
       " (32,\n",
       "  '0.038*证券 + 0.023*深度 + 0.018*成交 + 0.016*读者 + 0.015*利害 + 0.014*纯属 + 0.014*作者 + 0.013*风险 + 0.012*实务 + 0.012*澳洲'),\n",
       " (33,\n",
       "  '0.016*情绪 + 0.014*总是 + 0.011*不好 + 0.011*情感 + 0.011*司令 + 0.010*男人 + 0.010*最好 + 0.009*感到 + 0.009*有时 + 0.009*往往'),\n",
       " (34,\n",
       "  '0.035*高级 + 0.025*第三代 + 0.021*开发 + 0.019*验证 + 0.018*设计 + 0.016*家族 + 0.014*硕士 + 0.012*技能 + 0.010*系统 + 0.010*线路'),\n",
       " (35,\n",
       "  '0.082*主持人 + 0.046*网友 + 0.034*皇后 + 0.029*一下 + 0.023*建议 + 0.017*近代 + 0.014*女士 + 0.013*考前 + 0.013*出生 + 0.012*不行'),\n",
       " (36,\n",
       "  '0.096*国防部长 + 0.053*方案 + 0.045*改革 + 0.035*中方 + 0.022*承诺 + 0.020*亚太地区 + 0.019*武装部队 + 0.018*华为 + 0.015*意见 + 0.015*安排'),\n",
       " (37,\n",
       "  '0.042*人民币 + 0.036*贷款 + 0.035*银行 + 0.029*政策 + 0.021*运动员 + 0.021*金融 + 0.020*该部 + 0.019*内地 + 0.018*外汇 + 0.018*利率'),\n",
       " (38,\n",
       "  '0.171*战机 + 0.033*指挥所 + 0.019*突击 + 0.016*摄影 + 0.012*机身 + 0.011*操纵 + 0.010*皇家 + 0.009*器材 + 0.009*现役 + 0.009*三国'),\n",
       " (39,\n",
       "  '0.026*政治 + 0.025*翻译 + 0.023*西方 + 0.018*概念 + 0.013*合格 + 0.013*讨论 + 0.012*经营 + 0.012*宪法 + 0.011*学术 + 0.010*靶场'),\n",
       " (40,\n",
       "  '0.032*报纸 + 0.031*爆炸 + 0.027*死刑 + 0.016*媒体 + 0.016*教授 + 0.012*含有 + 0.011*新闻 + 0.011*营养 + 0.010*长时间 + 0.010*疲劳'),\n",
       " (41,\n",
       "  '0.292*台湾 + 0.057*国民党 + 0.049*搜狐 + 0.048*台当局 + 0.041*太平洋 + 0.032*李杰 + 0.023*两岸 + 0.020*台军方 + 0.017*共和国 + 0.014*命中'),\n",
       " (42,\n",
       "  '0.058*间谍 + 0.035*成员 + 0.026*武汉 + 0.019*友好 + 0.018*76 + 0.018*英特尔 + 0.018*不及 + 0.016*起降 + 0.016*侵入 + 0.012*甲板'),\n",
       " (43,\n",
       "  '0.060*核武器 + 0.049*老师 + 0.032*战士 + 0.014*女生 + 0.014*二号 + 0.013*学生 + 0.013*采访 + 0.013*音乐 + 0.012*一名 + 0.011*故事'),\n",
       " (44,\n",
       "  '0.048*申请 + 0.046*委员 + 0.021*贷款 + 0.021*委员会 + 0.020*执行 + 0.018*审核 + 0.017*取消 + 0.016*应当 + 0.015*公正 + 0.015*监督'),\n",
       " (45,\n",
       "  '0.016*全球 + 0.016*战车 + 0.012*2000 + 0.012*研发 + 0.011*数量 + 0.010*澳大利亚 + 0.010*工业 + 0.010*科技 + 0.009*35 + 0.009*2003'),\n",
       " (46,\n",
       "  '0.086*医院 + 0.036*儿童 + 0.030*if + 0.027*form + 0.026*医疗 + 0.018*医生 + 0.017*全场 + 0.016*华瑞 + 0.016*耐心 + 0.016*药物'),\n",
       " (47,\n",
       "  '0.052*微软 + 0.052*广告 + 0.036*电脑 + 0.030*在线 + 0.024*财年 + 0.023*屁股 + 0.019*推出 + 0.017*全球 + 0.016*软件 + 0.015*决战'),\n",
       " (48,\n",
       "  '0.083*导弹 + 0.066*作战 + 0.032*大陆 + 0.032*军队 + 0.023*军事 + 0.020*攻击 + 0.019*雷达 + 0.018*战略 + 0.018*联合 + 0.018*信息化'),\n",
       " (49,\n",
       "  '0.120*指挥 + 0.033*体育 + 0.030*空降 + 0.027*足球 + 0.027*世界杯 + 0.026*德国 + 0.024*成绩 + 0.019*大赛 + 0.012*选手 + 0.010*1951'),\n",
       " (50,\n",
       "  '0.084*人才 + 0.053*演练 + 0.052*招聘 + 0.047*面试 + 0.043*员工 + 0.035*职位 + 0.017*指挥员 + 0.016*经验 + 0.012*经理 + 0.012*求职者'),\n",
       " (51,\n",
       "  '0.102*法国 + 0.054*欧洲 + 0.040*携带 + 0.035*杨琳 + 0.027*赛季 + 0.026*条例 + 0.024*沈阳 + 0.022*意大利 + 0.019*派遣 + 0.019*87'),\n",
       " (52,\n",
       "  '0.074*陈水扁 + 0.071*航空 + 0.047*机场 + 0.036*试飞 + 0.036*飞机 + 0.030*场景 + 0.028*命题 + 0.019*航空公司 + 0.016*小时 + 0.015*加班'),\n",
       " (53,\n",
       "  '0.038*英语 + 0.029*工程 + 0.025*学院 + 0.023*教授 + 0.019*教学 + 0.019*培养 + 0.019*大学 + 0.015*科学 + 0.014*课程 + 0.014*数学'),\n",
       " (54,\n",
       "  '0.043*建设 + 0.017*安全 + 0.015*保障 + 0.014*加强 + 0.014*我国 + 0.011*体系 + 0.011*我军 + 0.011*革命 + 0.011*建立 + 0.010*利益'),\n",
       " (55,\n",
       "  '0.064*广东 + 0.057*玉山 + 0.052*深圳 + 0.044*执行 + 0.038*钓鱼岛 + 0.035*威慑 + 0.027*澳门 + 0.027*杭州 + 0.024*修改 + 0.022*制裁'),\n",
       " (56,\n",
       "  '0.090*和平 + 0.071*毛泽东 + 0.050*文章 + 0.050*红军 + 0.030*主席 + 0.030*中华 + 0.029*长征 + 0.026*针对性 + 0.026*高教 + 0.022*两国'),\n",
       " (57,\n",
       "  '0.113*军事 + 0.085*武器 + 0.078*空军 + 0.023*媒体 + 0.018*购买 + 0.016*太空 + 0.015*布什 + 0.015*用于 + 0.014*战略 + 0.014*摧毁'),\n",
       " (58,\n",
       "  '0.079*of + 0.054*公里 + 0.050*and + 0.037*起飞 + 0.024*空投 + 0.021*前往 + 0.020*公园 + 0.015*增援 + 0.014*小时 + 0.014*博物馆'),\n",
       " (59,\n",
       "  '0.035*治疗 + 0.032*女性 + 0.019*患者 + 0.017*病人 + 0.017*医生 + 0.017*检查 + 0.015*男性 + 0.015*手术 + 0.014*健康 + 0.014*疾病'),\n",
       " (60,\n",
       "  '0.180*the + 0.058*in + 0.041*is + 0.035*电话 + 0.031*短信 + 0.029*The + 0.029*日记 + 0.019*用户 + 0.018*手机 + 0.017*with'),\n",
       " (61,\n",
       "  '0.076*培训 + 0.070*学员 + 0.042*阿富汗 + 0.035*监视 + 0.034*三军 + 0.030*冷战 + 0.019*右派 + 0.017*推理 + 0.017*裁判 + 0.014*选举'),\n",
       " (62,\n",
       "  '0.107*演习 + 0.104*海军 + 0.037*官兵 + 0.029*军演 + 0.028*军事演习 + 0.026*以色列 + 0.023*司令部 + 0.021*部署 + 0.018*舰队 + 0.016*印度洋'),\n",
       " (63,\n",
       "  '0.023*潜艇 + 0.009*女人 + 0.009*男人 + 0.007*儿子 + 0.006*父亲 + 0.006*喜欢 + 0.005*朋友 + 0.005*女儿 + 0.005*母亲 + 0.004*爱情'),\n",
       " (64,\n",
       "  '0.025*合作 + 0.016*领域 + 0.013*创新 + 0.011*需求 + 0.010*模式 + 0.009*行业 + 0.009*战略 + 0.008*资源 + 0.008*平台 + 0.008*优势'),\n",
       " (65,\n",
       "  '0.072*会议 + 0.023*投票 + 0.021*召开 + 0.019*本次 + 0.017*股东 + 0.016*同意 + 0.014*地址 + 0.012*委托 + 0.012*征集 + 0.011*通知'),\n",
       " (66,\n",
       "  '0.209*资料 + 0.195*解放军 + 0.063*台军 + 0.035*国防 + 0.034*披露 + 0.030*媒体 + 0.019*台海 + 0.012*实力 + 0.012*部长 + 0.011*千克'),\n",
       " (67,\n",
       "  '0.051*毕业生 + 0.043*就业 + 0.027*简历 + 0.021*巴基斯坦 + 0.021*求职 + 0.018*招聘 + 0.013*单位 + 0.012*岗位 + 0.010*大学生 + 0.010*用人单位'),\n",
       " (68,\n",
       "  '0.127*美军 + 0.048*海上 + 0.040*空中 + 0.029*海域 + 0.025*舰艇 + 0.022*建造 + 0.019*大规模 + 0.018*军舰 + 0.014*这次 + 0.013*一艘'),\n",
       " (69,\n",
       "  '0.095*系统 + 0.065*防务 + 0.051*远程 + 0.051*机动 + 0.035*部署 + 0.034*武警 + 0.031*系列 + 0.029*采用 + 0.027*编队 + 0.025*工程师'),\n",
       " (70,\n",
       "  '0.077*考生 + 0.055*招生 + 0.049*考试 + 0.046*录取 + 0.040*学校 + 0.036*志愿 + 0.025*高考 + 0.022*成绩 + 0.020*院校 + 0.019*本科'),\n",
       " (71,\n",
       "  '0.086*队员 + 0.053*球员 + 0.029*越南 + 0.025*这支 + 0.022*连队 + 0.017*观摩 + 0.016*大地 + 0.015*军营 + 0.015*四级 + 0.014*一名'),\n",
       " (72,\n",
       "  '0.045*我军 + 0.030*政府 + 0.027*费用 + 0.026*收费 + 0.014*查询 + 0.014*交易 + 0.013*保卫 + 0.012*银行 + 0.011*购买 + 0.011*市民'),\n",
       " (73,\n",
       "  '0.063*to + 0.030*文学 + 0.017*城市 + 0.013*别墅 + 0.011*you + 0.011*雷声 + 0.011*后面 + 0.011*巡洋舰 + 0.010*模型 + 0.009*艺术家'),\n",
       " (74,\n",
       "  '0.161*伊朗 + 0.109*俄罗斯 + 0.053*伊拉克 + 0.039*苏联 + 0.024*总统 + 0.015*鱼雷 + 0.014*武装 + 0.014*服役 + 0.011*西方 + 0.011*石油'),\n",
       " (75,\n",
       "  '0.033*游戏 + 0.015*视察 + 0.011*灵魂 + 0.010*网络游戏 + 0.010*少年 + 0.009*当代 + 0.008*参数 + 0.008*赶到 + 0.006*关怀 + 0.006*面子'),\n",
       " (76,\n",
       "  '0.067*研制 + 0.053*飞机 + 0.044*发射 + 0.040*发动机 + 0.038*航母 + 0.029*航空工业 + 0.028*航空 + 0.026*新型 + 0.025*先进 + 0.023*自主'),\n",
       " (77,\n",
       "  '0.118*旅游 + 0.043*游客 + 0.024*旅行社 + 0.024*五一 + 0.023*黄金周 + 0.019*城市 + 0.016*酒店 + 0.016*景区 + 0.013*旅游局 + 0.012*接待'),\n",
       " (78,\n",
       "  '0.058*万人 + 0.047*斩首 + 0.043*同志 + 0.030*南京 + 0.025*人数 + 0.024*紧张 + 0.020*假期 + 0.020*自杀 + 0.019*红色 + 0.019*宣传部'),\n",
       " (79,\n",
       "  '0.027*食物 + 0.021*预防 + 0.017*食品 + 0.015*含量 + 0.015*使用寿命 + 0.014*调节 + 0.014*危险 + 0.014*死亡 + 0.014*脂肪 + 0.014*相适应'),\n",
       " (80,\n",
       "  '0.057*战场 + 0.041*核潜艇 + 0.036*网络 + 0.034*网站 + 0.024*网上 + 0.024*军用 + 0.018*南海 + 0.014*重庆 + 0.014*侵略 + 0.012*美方'),\n",
       " (81,\n",
       "  '0.023*身体 + 0.022*生成 + 0.021*方法 + 0.020*运动 + 0.019*状态 + 0.011*皮肤 + 0.009*物质 + 0.009*可怕 + 0.009*观察 + 0.009*体检'),\n",
       " (82,\n",
       "  '0.072*价格 + 0.044*药品 + 0.028*成本 + 0.020*国家队 + 0.018*名单 + 0.016*生产 + 0.015*年版 + 0.014*路边 + 0.012*中药 + 0.012*今年年初'),\n",
       " (83,\n",
       "  '0.061*18 + 0.059*17 + 0.057*22 + 0.053*14 + 0.048*16 + 0.047*19 + 0.046*29 + 0.046*00 + 0.045*21 + 0.043*13'),\n",
       " (84,\n",
       "  '0.038*干部 + 0.024*项羽 + 0.018*领导 + 0.018*表演 + 0.017*运动 + 0.016*外形 + 0.015*选拔 + 0.014*动作 + 0.014*讲话 + 0.012*主任'),\n",
       " (85,\n",
       "  '0.044*俱乐部 + 0.023*对手 + 0.020*谈判 + 0.012*民用 + 0.012*地带 + 0.011*在职 + 0.011*面对 + 0.011*回避 + 0.008*中国足协 + 0.008*史上'),\n",
       " (86,\n",
       "  '0.066*报考 + 0.050*报名 + 0.038*考核 + 0.031*步兵 + 0.028*档案 + 0.027*测试 + 0.025*服从 + 0.024*志愿 + 0.021*调剂 + 0.020*批次'),\n",
       " (87,\n",
       "  '0.201*印度 + 0.116*朝鲜 + 0.062*教练机 + 0.028*强国 + 0.019*南非 + 0.019*大国 + 0.018*埃及 + 0.013*文化遗产 + 0.011*长城 + 0.011*多用途'),\n",
       " (88,\n",
       "  '0.035*情报 + 0.027*乡村 + 0.020*成都 + 0.014*伤亡 + 0.012*路线 + 0.012*特色 + 0.010*休闲 + 0.009*大师 + 0.009*旅游 + 0.009*城市'),\n",
       " (89,\n",
       "  '0.092*飞机 + 0.084*一页 + 0.033*艺术 + 0.022*美日 + 0.020*奖励 + 0.018*遗址 + 0.017*东海 + 0.017*文物 + 0.015*立委 + 0.014*前线'),\n",
       " (90,\n",
       "  '0.026*码头 + 0.023*中型 + 0.021*领取 + 0.021*绘画 + 0.018*2011 + 0.016*动画 + 0.015*种子 + 0.015*病毒 + 0.014*指着 + 0.011*免费'),\n",
       " (91,\n",
       "  '0.053*坦克 + 0.035*将军 + 0.034*火力 + 0.023*官方 + 0.015*英雄 + 0.014*演出 + 0.012*批判 + 0.011*心灵 + 0.011*水域 + 0.010*生命'),\n",
       " (92,\n",
       "  '0.034*分钟 + 0.023*战舰 + 0.016*蓝军 + 0.016*主战 + 0.013*军事训练 + 0.012*隐身 + 0.011*炮弹 + 0.011*前面 + 0.010*得分 + 0.010*as'),\n",
       " (93,\n",
       "  '0.050*亿美元 + 0.027*for + 0.021*销售 + 0.020*大纲 + 0.019*周刊 + 0.015*罗马 + 0.013*计算机 + 0.013*工厂 + 0.012*裁员 + 0.011*单元'),\n",
       " (94,\n",
       "  '0.031*法律 + 0.014*行为 + 0.013*犯罪 + 0.010*案件 + 0.010*制度 + 0.009*身份 + 0.008*政府 + 0.008*权利 + 0.008*应当 + 0.008*家属'),\n",
       " (95,\n",
       "  '0.030*举行 + 0.017*炸弹 + 0.016*报告 + 0.016*官员 + 0.016*媒体 + 0.015*这次 + 0.015*威胁 + 0.014*宣布 + 0.012*弹药 + 0.011*总理'),\n",
       " (96,\n",
       "  '0.034*一枚 + 0.033*手机 + 0.024*移动 + 0.023*盟友 + 0.017*东南 + 0.015*资费 + 0.013*用户 + 0.012*电信 + 0.012*干线 + 0.012*套餐'),\n",
       " (97,\n",
       "  '0.113*防御 + 0.037*密码 + 0.034*客人 + 0.019*江西 + 0.013*来访 + 0.013*南昌 + 0.013*美国国务院 + 0.013*代理人 + 0.011*集团 + 0.011*ST'),\n",
       " (98,\n",
       "  '0.103*士兵 + 0.053*军人 + 0.027*单位 + 0.025*创业 + 0.022*航线 + 0.015*牺牲 + 0.015*it + 0.014*每周 + 0.013*职工 + 0.013*月薪'),\n",
       " (99,\n",
       "  '0.078*学生 + 0.053*孩子 + 0.042*学习 + 0.034*学校 + 0.032*大学 + 0.027*家长 + 0.026*同学 + 0.026*大学生 + 0.023*毕业 + 0.017*复习')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = lda_model.print_topics(-1)\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.47653010263610995\t Index: 61\t \n",
      "Topic: 0.120*集团 + 0.036*轻型 + 0.035*毫米 + 0.032*集团公司 + 0.024*增长\n",
      "Score: 0.21983220847303767\t Index: 2\t \n",
      "Topic: 0.032*行情 + 0.026*论坛 + 0.023*上涨 + 0.016*封锁 + 0.015*价格\n",
      "Score: 0.15082194075399588\t Index: 85\t \n",
      "Topic: 0.072*炸弹 + 0.060*一枚 + 0.043*空投 + 0.041*攻关 + 0.041*盟友\n",
      "Score: 0.08191578188618771\t Index: 88\t \n",
      "Topic: 0.035*保护 + 0.029*携带 + 0.026*条例 + 0.023*高原 + 0.021*航线\n",
      "Score: 0.030799234045441475\t Index: 36\t \n",
      "Topic: 0.109*美元 + 0.049*密码 + 0.035*后人 + 0.035*批次 + 0.030*英特尔\n",
      "Score: 0.0194951135374893\t Index: 24\t \n",
      "Topic: 0.169*旅游 + 0.058*游客 + 0.037*五一 + 0.029*黄金周 + 0.022*景区\n",
      "Score: 0.01111582274936802\t Index: 99\t \n",
      "Topic: 0.064*股东 + 0.046*股份 + 0.041*股权 + 0.024*公告 + 0.023*有限公司\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bag_of_words_corpus[3]], key=lambda tup: -1*tup[1]):\n",
    "    print (\"Score: {}\\t Index: {}\\t \\nTopic: {}\".format(score, index, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log perplexity of the model is -8.42597499017\n"
     ]
    }
   ],
   "source": [
    "print (\"Log perplexity of the model is\", lda_model.log_perplexity(bag_of_words_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C000007\t汽车\n",
    "C000008\t财经\n",
    "C000010\tIT\n",
    "C000013\t健康\n",
    "C000014\t体育\n",
    "C000016\t旅游\n",
    "C000020\t教育\n",
    "C000022\t招聘\n",
    "C000023\t文化\n",
    "C000024\t军事\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the dataset there are 10746 textual documents\n",
      "In the corpus there are 216313 unique tokens\n",
      "After filtering, in the corpus there are only 15697 unique tokens\n",
      "Running time: 775.6415254519088 Seconds\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.WARNING)\n",
    "logging.root.level = logging.WARNING\n",
    "import os\n",
    "import jieba\n",
    "import codecs\n",
    "import time\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "start = time.clock()\n",
    "def read_documents(file):\n",
    "    documents = []\n",
    "    walk = os.walk(file)\n",
    "    for root ,dirs, files in walk:\n",
    "        for name in files:\n",
    "            filename = os.path.join(root, name)\n",
    "            try:\n",
    "                f = open(filename)\n",
    "                #f = codecs.open(filename,'r','utf-8','ignore')\n",
    "                text = f.read()\n",
    "            except:\n",
    "                f = codecs.open(filename,'r','gbk','ignore')    \n",
    "                text = f.read()\n",
    "            finally:\n",
    "                f.close()\n",
    "\n",
    "            documents.append(text)\n",
    "    return documents\n",
    "#documents = news_dataset.data\n",
    "documents = read_documents('train')\n",
    "print (\"In the dataset there are\", len(documents), \"textual documents\")\n",
    "#print (\"And this is the first one:\\n\", documents[0])\n",
    "        \n",
    "def load_stopwords():\n",
    "    f_stop = open('stopwords.txt')\n",
    "    try:\n",
    "        f_stop_text = f_stop.read()\n",
    "\n",
    "    finally:\n",
    "        f_stop.close()\n",
    "\n",
    "    f_stop_seg_list = f_stop_text.split('\\n')\n",
    "    return f_stop_seg_list\n",
    "\n",
    "def tokenize(text):\n",
    "    stopwords = load_stopwords()    \n",
    "    return [token for token in jieba.cut(text) if token.strip() not in stopwords and len(token.strip()) > 1]\n",
    "\n",
    "#print (\"After the tokenizer, the previous document becomes:\\n\", tokenize(documents[0]))\n",
    "\n",
    "\n",
    "processed_docs = [tokenize(doc) for doc in documents]\n",
    "word_count_dict = gensim.corpora.Dictionary(processed_docs)\n",
    "print (\"In the corpus there are\", len(word_count_dict), \"unique tokens\")\n",
    "\n",
    "word_count_dict.filter_extremes(no_below=20, no_above=0.1)\n",
    "print (\"After filtering, in the corpus there are only\", len(word_count_dict), \"unique tokens\")\n",
    "\n",
    "bag_of_words_corpus = [word_count_dict.doc2bow(pdoc) for pdoc in processed_docs]\n",
    "\n",
    "#bow_doc1 = bag_of_words_corpus[0]\n",
    "#print (\"Bag of words representation of the first document (tuples are composed by token_id and multiplicity):\\n\", bow_doc1)\n",
    "#print\n",
    "#for i in range(5):\n",
    "#    print (\"In the document, topic_id {} (word \\\"{}\\\") appears {} time[s]\".format(bow_doc1[i][0], word_count_dict[bow_doc1[i][0]], bow_doc1[i][1]))\n",
    "#print (\"...\")\n",
    "\n",
    "\n",
    "# LDA mono-core\n",
    "lda_model = gensim.models.LdaModel(bag_of_words_corpus, num_topics=100,iterations=1000, id2word=word_count_dict, passes=5)\n",
    "\n",
    "# LDA multicore (in this configuration, defaulty, uses n_cores-1)\n",
    "# lda_model = gensim.models.LdaMulticore(bag_of_words_corpus, num_topics=10, id2word=word_count_dict, passes=5)\n",
    "\n",
    "#_ = lda_model.print_topics(-1)\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print('Running time: %s Seconds'%(end-start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the test dataset there are 7164 unseen textual documents\n",
      "Running time: 344.3479989507159 Seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "#for index, score in sorted(lda_model[bag_of_words_corpus[0]], key=lambda tup: -1*tup[1]):\n",
    "#    print (\"Score: {}\\t Index: {}\\t \\nTopic: {}\".format(score, index, lda_model.print_topic(index, 5)))\n",
    "\n",
    "\n",
    "unseen_documents = read_documents('test')\n",
    "print (\"In the test dataset there are\", len(unseen_documents), \"unseen textual documents\")\n",
    "\n",
    "processed_docs = [tokenize(doc) for doc in unseen_documents]\n",
    "#word_count_dict = gensim.corpora.Dictionary(processed_docs)\n",
    "#print (\"In the corpus there are\", len(word_count_dict), \"unique tokens\")\n",
    "\n",
    "#word_count_dict.filter_extremes(no_below=20, no_above=0.1)\n",
    "#print (\"After filtering, in the corpus there are only\", len(word_count_dict), \"unique tokens\")\n",
    "\n",
    "\n",
    "bow_vector = [word_count_dict.doc2bow(pdoc) for pdoc in processed_docs]\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print('Running time: %s Seconds'%(end-start))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.42451921271739806\t Index: 49\t \n",
      "Topic: 0.058*航母 + 0.048*香港 + 0.019*销售 + 0.018*西安 + 0.016*杨琳\n",
      "Score: 0.09377513906361076\t Index: 1\t \n",
      "Topic: 0.032*以色列 + 0.021*全球 + 0.015*报告 + 0.015*联合国 + 0.014*发言人\n",
      "Score: 0.0857502936132435\t Index: 2\t \n",
      "Topic: 0.047*网络 + 0.032*合作 + 0.031*网站 + 0.030*情报 + 0.023*平台\n",
      "Score: 0.07960287410114551\t Index: 40\t \n",
      "Topic: 0.038*集团 + 0.027*增长 + 0.020*航空 + 0.020*集团公司 + 0.020*行业\n",
      "Score: 0.04509019707217458\t Index: 67\t \n",
      "Topic: 0.046*股东 + 0.034*股份 + 0.029*股权 + 0.024*有限公司 + 0.021*应届\n",
      "Score: 0.039585804385504186\t Index: 16\t \n",
      "Topic: 0.109*台湾 + 0.069*大陆 + 0.025*军方 + 0.022*发动机 + 0.016*国民党\n",
      "Score: 0.037664175452381515\t Index: 93\t \n",
      "Topic: 0.113*调查 + 0.067*分钟 + 0.020*比例 + 0.016*受访者 + 0.016*37\n",
      "Score: 0.034316948851955756\t Index: 63\t \n",
      "Topic: 0.026*委员 + 0.022*执行 + 0.022*美日 + 0.020*委员会 + 0.019*申请\n",
      "Score: 0.03371176307582605\t Index: 84\t \n",
      "Topic: 0.075*战车 + 0.053*搜狐 + 0.045*体育 + 0.032*官方 + 0.030*赛季\n",
      "Score: 0.03351671202853204\t Index: 56\t \n",
      "Topic: 0.104*主持人 + 0.098*革命 + 0.082*青年 + 0.061*网友 + 0.030*沈阳\n",
      "Score: 0.03258064516129026\t Index: 90\t \n",
      "Topic: 0.045*for + 0.025*you + 0.023*词汇 + 0.023*客人 + 0.020*选项\n",
      "Score: 0.03149913770274245\t Index: 34\t \n",
      "Topic: 0.026*遗址 + 0.021*身体 + 0.019*可怕 + 0.018*损伤 + 0.017*重任\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_vector[1204]], key=lambda tup: -1*tup[1]):\n",
    "    print (\"Score: {}\\t Index: {}\\t \\nTopic: {}\".format(score, index,lda_model.print_topic(index, 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.043*17 + 0.042*18 + 0.039*22 + 0.039*14 + 0.038*16 + 0.035*13 + 0.033*19 + 0.030*25 + 0.028*21 + 0.024*35'),\n",
       " (1,\n",
       "  '0.032*以色列 + 0.021*全球 + 0.015*报告 + 0.015*联合国 + 0.014*发言人 + 0.013*布什 + 0.012*美元 + 0.010*伊朗核 + 0.010*宣布 + 0.010*政府'),\n",
       " (2,\n",
       "  '0.047*网络 + 0.032*合作 + 0.031*网站 + 0.030*情报 + 0.023*平台 + 0.019*指挥所 + 0.017*互联网 + 0.015*网上 + 0.013*IT + 0.012*业务'),\n",
       " (3,\n",
       "  '0.081*演习 + 0.022*战斗力 + 0.022*军演 + 0.021*军事演习 + 0.018*司令部 + 0.017*国防部 + 0.017*飞行员 + 0.014*隐形 + 0.013*舰队 + 0.011*印度洋'),\n",
       " (4,\n",
       "  '0.139*导弹 + 0.074*俄罗斯 + 0.053*系统 + 0.026*战略 + 0.019*弹道导弹 + 0.017*防空 + 0.017*火炮 + 0.016*防御 + 0.015*毫米 + 0.012*射程'),\n",
       " (5,\n",
       "  '0.114*战争 + 0.041*核武器 + 0.035*力量 + 0.020*变革 + 0.020*时代 + 0.016*快乐 + 0.015*冲突 + 0.015*世纪 + 0.014*方向 + 0.014*武力'),\n",
       " (6,\n",
       "  '0.056*05 + 0.051*04 + 0.044*数学 + 0.042*营养 + 0.029*75 + 0.021*奖学金 + 0.020*01 + 0.019*大赛 + 0.019*维生素 + 0.018*成绩'),\n",
       " (7,\n",
       "  '0.068*斩首 + 0.043*太阳 + 0.031*测量 + 0.025*带领 + 0.019*不仅如此 + 0.017*遭到 + 0.017*淘汰 + 0.016*首长 + 0.016*高层 + 0.014*地面'),\n",
       " (8,\n",
       "  '0.059*武器 + 0.039*军事 + 0.033*媒体 + 0.023*战场 + 0.019*对抗 + 0.017*打击 + 0.013*火力 + 0.012*秘密 + 0.011*大规模 + 0.011*摧毁'),\n",
       " (9,\n",
       "  '0.110*国防 + 0.070*一枚 + 0.052*基金 + 0.049*指数 + 0.048*伊万诺夫 + 0.047*盟友 + 0.032*军费 + 0.032*重型 + 0.022*发行 + 0.021*开支'),\n",
       " (10,\n",
       "  '0.075*发射 + 0.073*台军 + 0.033*卫星 + 0.028*披露 + 0.025*无人机 + 0.023*鱼雷 + 0.023*实施 + 0.021*图片 + 0.021*太空 + 0.019*任务'),\n",
       " (11,\n",
       "  '0.115*考试 + 0.068*成绩 + 0.039*课程 + 0.033*阅读 + 0.021*教材 + 0.017*概论 + 0.017*来源 + 0.014*教练 + 0.012*重点 + 0.012*授予'),\n",
       " (12,\n",
       "  '0.127*陈水扁 + 0.063*俱乐部 + 0.058*使命 + 0.051*特种部队 + 0.041*编队 + 0.021*马丁 + 0.019*惧怕 + 0.013*动手 + 0.013*上演 + 0.012*重返'),\n",
       " (13,\n",
       "  '0.019*作家 + 0.018*场景 + 0.016*小说 + 0.016*出版 + 0.013*人物 + 0.013*著名 + 0.012*作者 + 0.011*集团军 + 0.011*美丽 + 0.011*本书'),\n",
       " (14,\n",
       "  '0.042*手机 + 0.038*短信 + 0.027*广州 + 0.025*推出 + 0.018*价格 + 0.017*消费者 + 0.014*免费 + 0.014*用户 + 0.012*北京市 + 0.012*市民'),\n",
       " (15,\n",
       "  '0.056*家族 + 0.036*消费者 + 0.032*认证 + 0.031*合格 + 0.026*食品 + 0.025*品牌 + 0.024*消费 + 0.023*上海市 + 0.023*体验 + 0.016*女兵'),\n",
       " (16,\n",
       "  '0.109*台湾 + 0.069*大陆 + 0.025*军方 + 0.022*发动机 + 0.016*国民党 + 0.014*台军 + 0.014*建造 + 0.011*报告 + 0.011*战备 + 0.010*举行'),\n",
       " (17,\n",
       "  '0.070*法国 + 0.035*举行 + 0.032*酒店 + 0.032*澳大利亚 + 0.029*此次 + 0.023*举办 + 0.019*主席 + 0.015*新加坡 + 0.014*展览 + 0.014*澳门'),\n",
       " (18,\n",
       "  '0.103*雷达 + 0.024*实验 + 0.022*数据 + 0.019*收费 + 0.018*系统 + 0.015*接收 + 0.013*设备 + 0.012*通信 + 0.012*辐射 + 0.012*银行'),\n",
       " (19,\n",
       "  '0.058*研制 + 0.052*新型 + 0.051*装备 + 0.047*试验 + 0.036*设计 + 0.029*航空 + 0.027*信息化 + 0.026*系统 + 0.023*先进 + 0.020*航空工业'),\n",
       " (20,\n",
       "  '0.060*德国 + 0.055*英国 + 0.042*欧洲 + 0.021*微软 + 0.018*意大利 + 0.018*广告 + 0.016*软件 + 0.016*西班牙 + 0.014*前线 + 0.013*公园'),\n",
       " (21,\n",
       "  '0.118*gt + 0.065*翻译 + 0.043*创业 + 0.033*炮弹 + 0.030*it + 0.028*台北 + 0.028*儿童 + 0.027*效能 + 0.022*细菌 + 0.021*句子'),\n",
       " (22,\n",
       "  '0.126*学生 + 0.066*学校 + 0.038*老师 + 0.034*教师 + 0.023*孩子 + 0.020*教学 + 0.020*复习 + 0.014*考研 + 0.014*学费 + 0.013*岗位'),\n",
       " (23,\n",
       "  '0.035*直升机 + 0.019*敌人 + 0.014*阅读 + 0.013*小姐 + 0.012*理解 + 0.010*is + 0.009*正确 + 0.009*应急 + 0.009*The + 0.009*牺牲'),\n",
       " (24,\n",
       "  '0.128*攻击 + 0.075*推演 + 0.057*报纸 + 0.043*缩水 + 0.038*得分 + 0.036*35 + 0.031*岛内 + 0.028*必需 + 0.026*总分 + 0.021*地图'),\n",
       " (25,\n",
       "  '0.026*科技 + 0.020*教育部 + 0.020*工程 + 0.018*科研 + 0.018*成果 + 0.017*创新 + 0.015*奖励 + 0.015*同志 + 0.015*领导 + 0.014*重点'),\n",
       " (26,\n",
       "  '0.030*孩子 + 0.016*最好 + 0.012*头发 + 0.012*皮肤 + 0.011*大脑 + 0.010*每天 + 0.010*正常 + 0.010*眼睛 + 0.010*方法 + 0.009*伤害'),\n",
       " (27,\n",
       "  '0.024*老板 + 0.018*同事 + 0.016*朋友 + 0.013*办公室 + 0.010*职场 + 0.009*一家 + 0.009*上司 + 0.008*是不是 + 0.008*一下 + 0.008*招聘会'),\n",
       " (28,\n",
       "  '0.006*in + 0.005*面对 + 0.005*状态 + 0.004*压力 + 0.004*价值 + 0.004*命题 + 0.004*竞争 + 0.004*相当 + 0.004*情绪 + 0.004*肯定'),\n",
       " (29,\n",
       "  '0.086*白领 + 0.080*紧张 + 0.048*咨询 + 0.042*800 + 0.026*II + 0.024*热线 + 0.023*洛阳 + 0.022*拼命 + 0.021*婚礼 + 0.020*建议'),\n",
       " (30,\n",
       "  '0.439*训练 + 0.029*分队 + 0.024*课目 + 0.018*日常 + 0.013*当务之急 + 0.012*跟着 + 0.012*医学 + 0.010*指导 + 0.010*咖啡 + 0.010*兵种'),\n",
       " (31,\n",
       "  '0.082*考生 + 0.058*招生 + 0.049*录取 + 0.043*志愿 + 0.031*学校 + 0.027*高考 + 0.024*学院 + 0.021*高校 + 0.021*院校 + 0.021*本科'),\n",
       " (32,\n",
       "  '0.073*队员 + 0.051*球员 + 0.047*跳槽 + 0.033*空降兵 + 0.031*年薪 + 0.026*职业规划 + 0.024*薪酬 + 0.018*导游 + 0.017*一名 + 0.017*VS'),\n",
       " (33,\n",
       "  '0.026*万元 + 0.019*收入 + 0.018*工资 + 0.017*贷款 + 0.013*人民币 + 0.010*投资 + 0.009*2000 + 0.008*2004 + 0.008*政府 + 0.008*银行'),\n",
       " (34,\n",
       "  '0.026*遗址 + 0.021*身体 + 0.019*可怕 + 0.018*损伤 + 0.017*重任 + 0.016*恐怖 + 0.016*阳光 + 0.015*呼吸 + 0.014*全身 + 0.014*食物'),\n",
       " (35,\n",
       "  '0.038*音乐 + 0.032*奖金 + 0.032*立委 + 0.028*摄影 + 0.027*劳动 + 0.027*企图 + 0.023*劳动者 + 0.017*观看 + 0.016*力不从心 + 0.016*海面'),\n",
       " (36,\n",
       "  '0.063*运动 + 0.033*新式 + 0.024*科学家 + 0.019*西南 + 0.017*颜色 + 0.016*效果 + 0.014*调节 + 0.013*细胞 + 0.013*伊尔 + 0.013*反应'),\n",
       " (37,\n",
       "  '0.055*旅游 + 0.037*旅行社 + 0.030*乡村 + 0.023*起飞 + 0.015*空投 + 0.015*成都 + 0.014*博物馆 + 0.014*文物 + 0.013*休闲 + 0.013*代表团'),\n",
       " (38,\n",
       "  '0.075*比赛 + 0.047*侦察 + 0.020*联赛 + 0.019*球队 + 0.015*突袭 + 0.013*冠军 + 0.011*选手 + 0.011*主场 + 0.010*进球 + 0.010*小分队'),\n",
       " (39,\n",
       "  '0.064*00 + 0.044*com + 0.043*www + 0.028*搜狗 + 0.024*搜索 + 0.023*办理 + 0.017*工程师 + 0.017*sogou + 0.015*通知 + 0.015*手续'),\n",
       " (40,\n",
       "  '0.038*集团 + 0.027*增长 + 0.020*航空 + 0.020*集团公司 + 0.020*行业 + 0.019*亿元 + 0.018*航空公司 + 0.016*投资 + 0.010*成交 + 0.009*证券'),\n",
       " (41,\n",
       "  '0.067*苏联 + 0.032*玉山 + 0.028*旅客 + 0.027*重庆 + 0.025*铁路 + 0.023*航班 + 0.020*这支 + 0.019*样子 + 0.017*前往 + 0.017*两架'),\n",
       " (42,\n",
       "  '0.033*文学 + 0.022*公务员 + 0.012*夫人 + 0.011*敬业 + 0.009*每周 + 0.009*主人 + 0.007*白天 + 0.007*半个 + 0.007*借口 + 0.007*随便'),\n",
       " (43,\n",
       "  '0.096*朝鲜 + 0.085*孩子 + 0.057*毛泽东 + 0.040*红军 + 0.039*家长 + 0.033*游戏 + 0.029*父母 + 0.023*长征 + 0.018*子女 + 0.017*失业'),\n",
       " (44,\n",
       "  '0.044*大学 + 0.032*大学生 + 0.019*校园 + 0.018*毕业 + 0.013*高校 + 0.010*北大 + 0.010*年轻人 + 0.009*城市 + 0.008*同学 + 0.008*本科生'),\n",
       " (45,\n",
       "  '0.043*推荐 + 0.032*睡觉 + 0.028*指挥部 + 0.016*深度 + 0.016*耳朵 + 0.012*上升 + 0.012*交战 + 0.011*开关 + 0.010*捷径 + 0.010*孙中山'),\n",
       " (46,\n",
       "  '0.097*飞机 + 0.046*战斗机 + 0.044*战机 + 0.041*空军 + 0.040*飞行 + 0.022*武器装备 + 0.017*坦克 + 0.016*印度 + 0.014*战术 + 0.014*米格'),\n",
       " (47,\n",
       "  '0.043*建设 + 0.018*我国 + 0.015*印度 + 0.013*体系 + 0.012*加强 + 0.012*建立 + 0.011*一体化 + 0.011*安全 + 0.010*现代化 + 0.008*斗争'),\n",
       " (48,\n",
       "  '0.055*南京 + 0.052*教练机 + 0.044*高级 + 0.040*修理 + 0.037*东海 + 0.024*杭州 + 0.023*南非 + 0.019*多用途 + 0.019*苏州 + 0.019*替换'),\n",
       " (49,\n",
       "  '0.058*航母 + 0.048*香港 + 0.019*销售 + 0.018*西安 + 0.016*杨琳 + 0.016*越南 + 0.012*内地 + 0.012*中华 + 0.011*人士 + 0.011*埃及'),\n",
       " (50,\n",
       "  '0.040*射击 + 0.039*实战 + 0.022*东北 + 0.018*考古 + 0.016*支援 + 0.015*绿色 + 0.013*靶场 + 0.012*上空 + 0.011*发掘 + 0.011*研究所'),\n",
       " (51,\n",
       "  '0.049*有限公司 + 0.049*深圳 + 0.038*广东 + 0.019*拍卖 + 0.018*投资 + 0.017*资产 + 0.017*共和国 + 0.015*职工 + 0.014*亿元 + 0.013*会计'),\n",
       " (52,\n",
       "  '0.052*移动 + 0.037*手机 + 0.027*资费 + 0.027*用户 + 0.023*套餐 + 0.021*运营商 + 0.021*3G + 0.021*电信 + 0.021*本地 + 0.018*绘画'),\n",
       " (53,\n",
       "  '0.027*小时 + 0.015*车辆 + 0.014*阿富汗 + 0.014*汽车 + 0.013*月薪 + 0.012*检查 + 0.012*一天 + 0.011*三军 + 0.010*到达 + 0.009*坐在'),\n",
       " (54,\n",
       "  '0.022*担任 + 0.016*大纲 + 0.013*生涯 + 0.011*种种 + 0.011*总经理 + 0.010*主管 + 0.010*新人 + 0.010*助理 + 0.009*辞职 + 0.009*负责'),\n",
       " (55,\n",
       "  '0.046*招聘 + 0.036*人才 + 0.030*面试 + 0.023*职位 + 0.021*简历 + 0.014*艺术 + 0.014*经验 + 0.010*应聘 + 0.010*背景 + 0.009*精神'),\n",
       " (56,\n",
       "  '0.104*主持人 + 0.098*革命 + 0.082*青年 + 0.061*网友 + 0.030*沈阳 + 0.027*指示 + 0.020*兴趣 + 0.013*主任 + 0.012*效果 + 0.010*网民'),\n",
       " (57,\n",
       "  '0.010*心情 + 0.009*足球 + 0.008*一场 + 0.008*两年 + 0.008*天下 + 0.007*女子 + 0.006*支援 + 0.006*这位 + 0.006*爸爸 + 0.006*刚刚'),\n",
       " (58,\n",
       "  '0.175*战斗 + 0.061*药品 + 0.030*采购 + 0.023*军火 + 0.022*评选 + 0.019*英特尔 + 0.019*挑衅 + 0.018*制药 + 0.018*招标 + 0.016*同盟'),\n",
       " (59,\n",
       "  '0.061*干部 + 0.042*公开 + 0.036*权力 + 0.036*领导 + 0.030*我军 + 0.028*和平 + 0.023*案件 + 0.022*民主 + 0.019*工厂 + 0.019*千克'),\n",
       " (60,\n",
       "  '0.034*监视 + 0.023*宪法 + 0.022*旅行 + 0.021*&# + 0.019*谈话 + 0.017*轰炸 + 0.017*教科书 + 0.016*战时 + 0.016*零件 + 0.015*8226'),\n",
       " (61,\n",
       "  '0.171*the + 0.090*of + 0.086*to + 0.030*that + 0.022*are + 0.021*be + 0.017*with + 0.017*先发制人 + 0.017*as + 0.012*at'),\n",
       " (62,\n",
       "  '0.025*制度 + 0.017*改革 + 0.015*实行 + 0.014*质量 + 0.013*规范 + 0.013*题目 + 0.012*教授 + 0.010*办法 + 0.009*实施 + 0.009*制定'),\n",
       " (63,\n",
       "  '0.026*委员 + 0.022*执行 + 0.022*美日 + 0.020*委员会 + 0.019*申请 + 0.019*应当 + 0.015*犯罪 + 0.014*程序 + 0.013*材料 + 0.012*保密'),\n",
       " (64,\n",
       "  '0.016*炸弹 + 0.016*城市 + 0.014*反恐 + 0.012*封锁 + 0.012*区域 + 0.010*当地 + 0.008*人口 + 0.007*别墅 + 0.007*首都 + 0.006*建筑'),\n",
       " (65,\n",
       "  '0.145*职业 + 0.080*培训 + 0.066*人才 + 0.049*学员 + 0.037*行业 + 0.022*需求 + 0.019*要素 + 0.018*知识 + 0.016*炮兵 + 0.016*军兵种'),\n",
       " (66,\n",
       "  '0.136*法律 + 0.062*方案 + 0.051*律师 + 0.050*独立 + 0.031*安排 + 0.029*承诺 + 0.029*意见 + 0.025*协商 + 0.024*支付 + 0.022*履行'),\n",
       " (67,\n",
       "  '0.046*股东 + 0.034*股份 + 0.029*股权 + 0.024*有限公司 + 0.021*应届 + 0.017*审议 + 0.016*董事会 + 0.016*公告 + 0.014*本次 + 0.012*流通股'),\n",
       " (68,\n",
       "  '0.045*治疗 + 0.040*医院 + 0.025*医生 + 0.023*女性 + 0.023*患者 + 0.020*病人 + 0.020*疾病 + 0.018*手术 + 0.017*死刑 + 0.017*健康'),\n",
       " (69,\n",
       "  '0.121*作战 + 0.063*潜艇 + 0.043*军队 + 0.019*核潜艇 + 0.013*空中 + 0.010*模拟 + 0.010*一支 + 0.009*军用 + 0.009*博士 + 0.009*防卫'),\n",
       " (70,\n",
       "  '0.090*士兵 + 0.046*军人 + 0.020*系列 + 0.017*电影 + 0.017*战士 + 0.013*希腊 + 0.013*派遣 + 0.011*第五代 + 0.010*an + 0.010*艺术品'),\n",
       " (71,\n",
       "  '0.063*亿美元 + 0.047*价格 + 0.030*增长 + 0.026*东南 + 0.025*单元 + 0.024*轻型 + 0.024*成本 + 0.018*下降 + 0.017*避开 + 0.016*全球'),\n",
       " (72,\n",
       "  '0.049*电话 + 0.041*表演 + 0.033*先生 + 0.030*新华社 + 0.023*外形 + 0.016*一会儿 + 0.016*大队 + 0.016*密码 + 0.014*全场 + 0.013*兼职'),\n",
       " (73,\n",
       "  '0.016*身体 + 0.012*休息 + 0.011*晚上 + 0.010*公主 + 0.009*美女 + 0.009*过来 + 0.009*一下 + 0.008*衣服 + 0.008*穿着 + 0.008*放松'),\n",
       " (74,\n",
       "  '0.235*韩国 + 0.031*妇女 + 0.031*大连 + 0.022*部属 + 0.019*日后 + 0.019*年龄 + 0.017*怀孕 + 0.012*分析家 + 0.011*婴儿 + 0.011*宝宝'),\n",
       " (75,\n",
       "  '0.069*武警 + 0.067*计算机 + 0.059*间谍 + 0.056*预警 + 0.047*电脑 + 0.031*该部 + 0.026*长假 + 0.025*五一 + 0.020*赔偿 + 0.020*感染'),\n",
       " (76,\n",
       "  '0.064*反对 + 0.058*同意 + 0.041*步枪 + 0.035*代表 + 0.032*搜集 + 0.028*100 + 0.026*江苏 + 0.025*会议 + 0.025*先生 + 0.024*召开'),\n",
       " (77,\n",
       "  '0.027*男人 + 0.026*喜欢 + 0.025*女人 + 0.013*同学 + 0.013*女性 + 0.013*总是 + 0.012*对方 + 0.011*爱情 + 0.010*感情 + 0.009*家庭'),\n",
       " (78,\n",
       "  '0.052*生产 + 0.025*基地 + 0.023*集团 + 0.022*研发 + 0.017*发动机 + 0.017*开发 + 0.015*国产 + 0.013*火箭 + 0.013*制造 + 0.013*现役'),\n",
       " (79,\n",
       "  '0.066*论坛 + 0.046*西部 + 0.038*西藏 + 0.037*新疆 + 0.025*海南 + 0.024*四川 + 0.023*资源 + 0.023*行情 + 0.018*万吨 + 0.017*打交道'),\n",
       " (80,\n",
       "  '0.071*会议 + 0.021*代表 + 0.017*召开 + 0.017*发言 + 0.016*政客 + 0.014*屁股 + 0.014*投票 + 0.012*胜任 + 0.012*领导人 + 0.011*少年'),\n",
       " (81,\n",
       "  '0.042*科目 + 0.022*行情 + 0.016*投资者 + 0.014*风险 + 0.014*论坛 + 0.013*上涨 + 0.013*外汇 + 0.013*股市 + 0.011*个股 + 0.011*大盘'),\n",
       " (82,\n",
       "  '0.191*解放军 + 0.164*资料 + 0.029*文章 + 0.022*不仅如此 + 0.019*保护 + 0.018*条例 + 0.014*实施 + 0.013*大规模 + 0.013*公开 + 0.013*中央'),\n",
       " (83,\n",
       "  '0.195*日本 + 0.024*合作 + 0.021*自卫队 + 0.017*利益 + 0.016*大国 + 0.016*两国 + 0.013*外交 + 0.012*双方 + 0.012*和平 + 0.011*威胁'),\n",
       " (84,\n",
       "  '0.075*战车 + 0.053*搜狐 + 0.045*体育 + 0.032*官方 + 0.030*赛季 + 0.030*世界杯 + 0.026*对手 + 0.026*东部 + 0.025*击败 + 0.020*领先'),\n",
       " (85,\n",
       "  '0.032*将军 + 0.024*政治 + 0.022*蒋介石 + 0.020*势力 + 0.017*节目 + 0.016*观众 + 0.013*路线 + 0.013*思想 + 0.011*出版社 + 0.011*隐蔽'),\n",
       " (86,\n",
       "  '0.161*演练 + 0.072*小组 + 0.048*总理 + 0.047*成员 + 0.042*登陆 + 0.018*顺利完成 + 0.016*画家 + 0.015*博客 + 0.015*参与 + 0.014*会见'),\n",
       " (87,\n",
       "  '0.118*毕业生 + 0.102*就业 + 0.045*求职 + 0.025*用人单位 + 0.021*线路 + 0.021*单位 + 0.019*大学生 + 0.013*旅游 + 0.010*宾馆 + 0.009*机场'),\n",
       " (88,\n",
       "  '0.015*儿子 + 0.013*父亲 + 0.011*终于 + 0.011*女儿 + 0.010*母亲 + 0.008*妻子 + 0.008*来到 + 0.008*离开 + 0.008*当年 + 0.008*丈夫'),\n",
       " (89,\n",
       "  '0.083*部队 + 0.059*海军 + 0.054*军事 + 0.030*任务 + 0.021*指挥 + 0.021*联合 + 0.020*官兵 + 0.020*部署 + 0.017*安全 + 0.016*行动'),\n",
       " (90,\n",
       "  '0.045*for + 0.025*you + 0.023*词汇 + 0.023*客人 + 0.020*选项 + 0.020*回去 + 0.017*122 + 0.016*感谢 + 0.016*缺点 + 0.014*吸收'),\n",
       " (91,\n",
       "  '0.069*学习 + 0.050*一页 + 0.031*员工 + 0.025*方法 + 0.019*知识 + 0.012*招收 + 0.009*心理 + 0.009*努力 + 0.008*自学 + 0.008*思维'),\n",
       " (92,\n",
       "  '0.046*我军 + 0.020*民族 + 0.014*政权 + 0.014*自由 + 0.014*日军 + 0.013*笔者 + 0.013*照片 + 0.010*公元 + 0.010*军区 + 0.009*共产党'),\n",
       " (93,\n",
       "  '0.113*调查 + 0.067*分钟 + 0.020*比例 + 0.016*受访者 + 0.016*37 + 0.015*平均 + 0.014*詹姆斯 + 0.013*生长 + 0.013*最高 + 0.013*数据'),\n",
       " (94,\n",
       "  '0.090*英语 + 0.032*语言 + 0.016*客户 + 0.013*单词 + 0.011*HR + 0.011*练习 + 0.011*汉语 + 0.011*含量 + 0.011*使用寿命 + 0.010*适合'),\n",
       " (95,\n",
       "  '0.139*旅游 + 0.072*游客 + 0.057*防务 + 0.036*黄金周 + 0.033*五一 + 0.026*景区 + 0.022*俄军 + 0.021*旅游局 + 0.021*乌克兰 + 0.016*图库'),\n",
       " (96,\n",
       "  '0.153*伊朗 + 0.051*伊拉克 + 0.028*西方 + 0.024*总统 + 0.018*年代 + 0.015*武装 + 0.013*苏联 + 0.011*袭击 + 0.011*石油 + 0.010*政治'),\n",
       " (97,\n",
       "  '0.068*美军 + 0.026*海上 + 0.015*空中 + 0.014*军队 + 0.013*海域 + 0.010*军舰 + 0.008*太平洋 + 0.007*学者 + 0.007*一艘 + 0.006*看见'),\n",
       " (98,\n",
       "  '0.076*作品 + 0.034*创作 + 0.031*生命 + 0.025*武汉 + 0.025*球迷 + 0.023*女士 + 0.023*红色 + 0.016*选拔 + 0.015*杨琳 + 0.014*证书'),\n",
       " (99,\n",
       "  '0.085*and + 0.052*拦截 + 0.051*万人 + 0.037*if + 0.031*威慑 + 0.031*form + 0.028*设施 + 0.025*is + 0.023*巡逻 + 0.023*not')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = lda_model.print_topics(-1)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.interfaces.TransformedCorpus object at 0x000000000443E048>\n"
     ]
    }
   ],
   "source": [
    "print (lda_model[bow_vector])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2596375225121668\t Index: 62\t \n",
      "Topic: 0.025*制度 + 0.017*改革 + 0.015*实行 + 0.014*质量 + 0.013*规范\n",
      "Score: 0.16815571676100544\t Index: 33\t \n",
      "Topic: 0.026*万元 + 0.019*收入 + 0.018*工资 + 0.017*贷款 + 0.013*人民币\n",
      "Score: 0.10747292651282023\t Index: 64\t \n",
      "Topic: 0.016*炸弹 + 0.016*城市 + 0.014*反恐 + 0.012*封锁 + 0.012*区域\n",
      "Score: 0.09301956756022667\t Index: 99\t \n",
      "Topic: 0.085*and + 0.052*拦截 + 0.051*万人 + 0.037*if + 0.031*威慑\n",
      "Score: 0.07706781949469757\t Index: 18\t \n",
      "Topic: 0.103*雷达 + 0.024*实验 + 0.022*数据 + 0.019*收费 + 0.018*系统\n",
      "Score: 0.04245851802295758\t Index: 97\t \n",
      "Topic: 0.068*美军 + 0.026*海上 + 0.015*空中 + 0.014*军队 + 0.013*海域\n",
      "Score: 0.038905014053826056\t Index: 63\t \n",
      "Topic: 0.026*委员 + 0.022*执行 + 0.022*美日 + 0.020*委员会 + 0.019*申请\n",
      "Score: 0.03831571249242904\t Index: 14\t \n",
      "Topic: 0.042*手机 + 0.038*短信 + 0.027*广州 + 0.025*推出 + 0.018*价格\n",
      "Score: 0.03603759552054761\t Index: 66\t \n",
      "Topic: 0.136*法律 + 0.062*方案 + 0.051*律师 + 0.050*独立 + 0.031*安排\n",
      "Score: 0.025780127041983233\t Index: 6\t \n",
      "Topic: 0.056*05 + 0.051*04 + 0.044*数学 + 0.042*营养 + 0.029*75\n",
      "Score: 0.02175931285113395\t Index: 96\t \n",
      "Topic: 0.153*伊朗 + 0.051*伊拉克 + 0.028*西方 + 0.024*总统 + 0.018*年代\n",
      "Score: 0.02053409200167578\t Index: 47\t \n",
      "Topic: 0.043*建设 + 0.018*我国 + 0.015*印度 + 0.013*体系 + 0.012*加强\n",
      "Score: 0.014686357162407999\t Index: 45\t \n",
      "Topic: 0.043*推荐 + 0.032*睡觉 + 0.028*指挥部 + 0.016*深度 + 0.016*耳朵\n",
      "Score: 0.01308341910434805\t Index: 70\t \n",
      "Topic: 0.090*士兵 + 0.046*军人 + 0.020*系列 + 0.017*电影 + 0.017*战士\n",
      "Score: 0.011747091343717353\t Index: 48\t \n",
      "Topic: 0.055*南京 + 0.052*教练机 + 0.044*高级 + 0.040*修理 + 0.037*东海\n",
      "Score: 0.011599659415771235\t Index: 68\t \n",
      "Topic: 0.045*治疗 + 0.040*医院 + 0.025*医生 + 0.023*女性 + 0.023*患者\n",
      "Score: 0.010909760914241558\t Index: 84\t \n",
      "Topic: 0.075*战车 + 0.053*搜狐 + 0.045*体育 + 0.032*官方 + 0.030*赛季\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_vector[2089]], key=lambda tup: -1*tup[1]):\n",
    "    print (\"Score: {}\\t Index: {}\\t \\nTopic: {}\".format(score, index,lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unseen document is composed by the following text: 　　本报记者王珍发自广州\n",
      "　　河北沧州献县的家电经销商王凤恩，2005年年中将自己的小店改为“幸福树电器连锁店”。“大卖场步步紧逼，员工素质低，信息闭塞，制造商吸钱。”王凤恩说，这四大困难使他选择了加盟幸福树。\n",
      "　　现在，已经有超过180个像王凤恩这样的农村家电经销商，成了由TCL控股的“幸福树电器连锁”的加盟商。而在浙江，也有100个这样的农村家电经销商，投入了创维加盟店的“怀抱”。\n",
      "　　王凤恩们没想到的是，在“建设社会主义新农村”的背景下，在家电厂商的利益拉锯中，他们这些偏安一隅的乡镇小商人，已变为被争夺的资源，因为家电制造商们正在抢建“第三渠道”。\n",
      "　　开辟“第三渠道”\n",
      "　　如果说去年家电厂对于自己涉足渠道还遮遮掩掩，那么，今年它们已经不怕公开亮相了。\n",
      "　　3月30日，幸福树打破缄默，在北京高调提出，今年将开发云、贵、川、晋、陕等14个省，加盟店增加到800家；以“一县一店”的规划，三年之内在全国建2000家店，形成对三、四级市场的完全覆盖。\n",
      "　　创维则把“试水”范围，圈定在浙江省发达的乡镇。创维浙江、福建分部总经理黄心仲向《第一财经(相关:理财 证券)日报》透露，自2005年12月以来，创维加盟店已发展到100家，分布在浙江100个镇上。“今年的目标是开到200家。浙江省境内共有1600个镇，按一镇一店的计划，尽快覆盖500~600个镇是有可能的。”\n",
      "　　为什么要开这些店呢？用创维集团副总裁、彩电事业部总裁杨东文的话是“开辟‘第三渠道’”，在大卖场和传统经销商之外，寻求“渠道创新”。\n",
      "　　经过调研，创维发现，一、二级市场的机会已经不大。黄心仲说，从最近永乐大中的合并可以看出，一、二级市场的家电渠道已经基本成熟，很难再产生新渠道。相比之下，三、四级市场正在发展，尤其四级乡镇市场还有很大机会。\n",
      "　　今年国家提出建设“社会主义新农村”，“中国9.5亿农民的购买力可是一座金矿！”黄心仲说，农村市场消费分散；业态落后，夫妻店居多；假冒伪劣产品横行，产品不新，价格却平均比城市贵10%，老百姓渴望信誉佳、运作好的商店。所以，“这里极有可能形成新的商圈”。\n",
      "　　幸福树电器连锁的总经理张付民也直言不讳：三、四级市场占全国市场半壁江山，且每年保持15%的增长；而三、四级市场又亟须整合，连锁将是必然趋势。\n",
      "　　“当前中国许多大型企业都自建营销网络、自己配送，资源耗费严重，而中小企业则因实力不足根本无法进入三、四级市场。”张付民说，幸福树希望通过优化供应链，做好制造商和单个零售商无法做好的事情。\n",
      "　　其实何止TCL、创维，作为家电制造商自建渠道的“先锋”，格力专卖店至今在国内已超过2500家；美的、志高去年也提出开展“上山下乡”运动、“千店工程”等。\n",
      "　　争夺农村市场\n",
      "　　与格力专卖店“城乡通吃”不同的是，新一轮的家电企业涉足渠道，主要锁定潜力巨大的农村市场。不过，农村市场犹如一块沼泽地，全国有上万个乡镇，面对如此分散的市场，如何操作才不至于泥足深陷、难以自拔？\n",
      "　　利用社会资源，拓展加盟店而非直营店，是制造商的新思路。\n",
      "　　为什么要吸引当地老板投资而不由厂家自己投资呢？黄心仲认为，乡镇必须依靠镇级的客户资源，不可能由创维的员工跑到乡镇去当老板；而且，本地人在当地人脉关系广、情况熟悉。所以，要让每个加盟商继续做老板，创维只对加盟店统一VI（视觉识别系统）、管理模式、物流体系、营销方法、财务系统，帮助这些当地老板提升管理能力。\n",
      "　　有了这些加盟店之后，创维在乡镇一级市场的信息流、服务流、产品流就畅通多了。老百姓可以在店内看到最新的产品、价格信息，创维也可以提供及时服务。黄心仲说：“运作半年，创维在这些地方的销售质量得到提升，以前乡镇消费的都是低端产品，现在乡镇老百姓也买中、高端的产品，实现消费者、经销商、厂家‘三赢’。”\n",
      "　　幸福树连锁在2004年底筹备之时，就彻底放弃了直营店模式。张付民认为，加盟店可以快速编网，降低物流、信息系统的成本；同时可以最大限度盘活社会资源，包括农村夫妻店的店面资源、顾客群；还可以充分发挥店主的主观能动性。而且，如果新建直营店，必然造成三、四级市场新的竞争冲突。\n",
      "　　“欧洲也有这样的加盟连锁店。”张付民介绍说，欧洲的Expretor（音）与幸福树类似，专门解决特大型城市之外分散城市里，经销商的物流配送、IT系统、采购平台和品牌统一输出的问题。Expretor已经有十年历史，欧洲虽然有“大地”、“迈地亚（Media）”等大卖场直营店，但Expretor仍然发挥着它对分散的“Papamama(爸爸妈妈)”店（即“夫妻店”）的支持作用。\n",
      "　　张付民指出，农村市场最大的难点，就在于分销成本过高。中国农村地域分散、幅员辽阔，使它的沟通成本比中心城市高得多。他举例说，过去很多企业开拓农村市场，往往是业务员坐着长途巴士“下乡”，带着产品图、价格表和销售政策，一周跑完十个县已不错。这不仅时间滞后，沟通效果还会因不同业务员而有差异。\n",
      "　　为了缩短总部与各分部以及各加盟店之间的“距离”，幸福树打造了一套计算机系统——幸福树DD网。张付民说：“我们把产品的照片挂上网去，同时介绍产品的卖点、销售政策，这样，一是没有信息传递的时延，二是沟通效果不再取决于人为因素，三是可以网上下订单。”\n",
      "　　据记者了解，幸福树、创维对每个加盟商均收取几万元的加盟费。\n",
      "　　记者观察\n",
      "　　“背离”大卖场？\n",
      "　　近年，国美、苏宁、永乐等电器大卖场连锁店在中国主要的中心城市犹如急风骤雨，不断攻城略地。伴随着它们店数的增加，对家电企业的压价也越来越厉害，厂商矛盾一度激化。\n",
      "　　如今，TCL、创维等厂家在三、四级市场涉足渠道，是否是对大卖场的一种“背离”？创维集团中国区域营销总部副总经理兼广东分部总经理刘桥明，并不认同“背离”一说。\n",
      "　　他说，对比百货、个体专营店，大卖场作为一种新兴业态，有着其天然的优势：一是品种大而全、高中低档都有，满足消费者一站式购物的需要。而且，它们都是民营企业，有着严格的考核、激励制度，所以，虽然厂商之间有摩擦，但也不能掩盖它们的优势。\n",
      "　　但是，今后随着国美、苏宁等大卖场向三、四级市场渗透，上述厂家自建的渠道必然不可避免地与其发生冲突，如何协调呢？\n",
      "　　创维强调，它的加盟店只在镇一级（即四级市场）发展。幸福树也明确表示，不会进入城市，而且它现在布局的重点也在中国中西部地区，而非东部沿海发达地区。\n",
      "　　有业内人士认为，国美苏宁直营店的模式并不适合在农村发展：在如此分散的市场开设直营店，必将难以管理，也很难分摊成本。但是，如果国美、苏宁在农村开加盟店，则其加盟店与直营店将形成内部冲突，毕竟加盟店的采购成本要比直营店高。\n",
      "　　国美董事长黄光裕在今年4月提出，以采购价增加一个百分点的价格，将电器批发给农村的经销商。有业内人士分析道，与其这样，农村经销商为什么不直接与厂家合作呢？\n",
      "　　新的问题是，只卖一家的产品能维持加盟店的盈利、吸引农村的经销商吗？不同厂家，各施各法。格力建的是专卖店，只做格力空调、小家电,毕竟空调还有安装费可以赚；创维加盟店，允许主推创维的彩电的前提下，冰箱、空调等可以做别的牌子；幸福树电器连锁则强调自己“是一个投资多元，品牌独立，公开、中立的商业零售企业”，不会只做TCL的产品。\n",
      "　　国美、TCL、创维等商家的纷至沓来，令农村电器市场逐渐呈现群雄并起的局面。一位家电业资深人士认为，无论大家以什么方式切入，目的都是一样的：让农村市场的零售网点从无到有，从无序到有序，从分散到统一。\n",
      "　　农村电器零售店分散、单店规模小、经营者水平参差不齐。因此，家电厂商都不约而同地希望摸索一套可以统一经营、自身可以复制的模式，来抢吃农村市场的蛋糕。“农村电器市场肯定也会像城市一样，有一个优胜劣汰的洗牌过程，目前农村的渠道竞争才刚刚开始。”\n",
      "Score: 0.2914965318669194\t Index: 49\t \n",
      "Topic: 0.058*航母 + 0.048*香港 + 0.019*销售 + 0.018*西安 + 0.016*杨琳\n",
      "Score: 0.16249938822684817\t Index: 96\t \n",
      "Topic: 0.153*伊朗 + 0.051*伊拉克 + 0.028*西方 + 0.024*总统 + 0.018*年代\n",
      "Score: 0.09875000461516277\t Index: 47\t \n",
      "Topic: 0.043*建设 + 0.018*我国 + 0.015*印度 + 0.013*体系 + 0.012*加强\n",
      "Score: 0.0636089545121034\t Index: 33\t \n",
      "Topic: 0.026*万元 + 0.019*收入 + 0.018*工资 + 0.017*贷款 + 0.013*人民币\n",
      "Score: 0.04540963081370096\t Index: 28\t \n",
      "Topic: 0.006*in + 0.005*面对 + 0.005*状态 + 0.004*压力 + 0.004*价值\n",
      "Score: 0.04533382090102565\t Index: 71\t \n",
      "Topic: 0.063*亿美元 + 0.047*价格 + 0.030*增长 + 0.026*东南 + 0.025*单元\n",
      "Score: 0.04249672969220306\t Index: 2\t \n",
      "Topic: 0.047*网络 + 0.032*合作 + 0.031*网站 + 0.030*情报 + 0.023*平台\n",
      "Score: 0.04146502578932129\t Index: 62\t \n",
      "Topic: 0.025*制度 + 0.017*改革 + 0.015*实行 + 0.014*质量 + 0.013*规范\n",
      "Score: 0.03141622016857077\t Index: 59\t \n",
      "Topic: 0.061*干部 + 0.042*公开 + 0.036*权力 + 0.036*领导 + 0.030*我军\n",
      "Score: 0.026757646287998937\t Index: 64\t \n",
      "Topic: 0.016*炸弹 + 0.016*城市 + 0.014*反恐 + 0.012*封锁 + 0.012*区域\n",
      "Score: 0.022301783465909872\t Index: 58\t \n",
      "Topic: 0.175*战斗 + 0.061*药品 + 0.030*采购 + 0.023*军火 + 0.022*评选\n",
      "Score: 0.017351122123084674\t Index: 27\t \n",
      "Topic: 0.024*老板 + 0.018*同事 + 0.016*朋友 + 0.013*办公室 + 0.010*职场\n",
      "Score: 0.013382084279989784\t Index: 42\t \n",
      "Topic: 0.033*文学 + 0.022*公务员 + 0.012*夫人 + 0.011*敬业 + 0.009*每周\n",
      "Score: 0.011980904449759964\t Index: 40\t \n",
      "Topic: 0.038*集团 + 0.027*增长 + 0.020*航空 + 0.020*集团公司 + 0.020*行业\n",
      "Score: 0.011691582849118793\t Index: 78\t \n",
      "Topic: 0.052*生产 + 0.025*基地 + 0.023*集团 + 0.022*研发 + 0.017*发动机\n",
      "Score: 0.011499568157528587\t Index: 44\t \n",
      "Topic: 0.044*大学 + 0.032*大学生 + 0.019*校园 + 0.018*毕业 + 0.013*高校\n",
      "Score: 0.010096486871915548\t Index: 20\t \n",
      "Topic: 0.060*德国 + 0.055*英国 + 0.042*欧洲 + 0.021*微软 + 0.018*意大利\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"21.txt\") as f:\n",
    "    unseen_document = f.read()\n",
    "\n",
    "print (\"The unseen document is composed by the following text:\", unseen_document)\n",
    "print\n",
    "\n",
    "bow_vector1 = word_count_dict.doc2bow(tokenize(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector1], key=lambda tup: -1*tup[1]):\n",
    "    print (\"Score: {}\\t Index: {}\\t \\nTopic: {}\".format(score, index,lda_model.print_topic(index, 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
